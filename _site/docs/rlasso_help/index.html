<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.11.1 by Michael Rose
  Copyright 2013-2018 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Help file: rlasso - The Stata Lasso Page</title>
<meta name="description" content="The Stata Lasso Page.">



<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="The Stata Lasso Page">
<meta property="og:title" content="Help file: rlasso">
<meta property="og:url" content="http://localhost:4000/docs/rlasso_help/">












  

  


<link rel="canonical" href="http://localhost:4000/docs/rlasso_help/">







  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "Achim Ahrens",
      "url": "http://localhost:4000",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="The Stata Lasso Page Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single wide">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="/">The Stata Lasso Page</a>
        <ul class="visible-links">
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/" >Home</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/installation/" >Installation</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/about/" >About</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/references/" >References</a>
            </li>
          
        </ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle Menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  
  
    
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle Menu</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">lassopack</span>
        

        
        <ul>
          
            
            

            
            

            <li><a href="/docs/lassopack/" class="">Overview</a></li>
          
            
            

            
            

            <li><a href="/docs/regularized_reg/" class="">Regularized regression</a></li>
          
            
            

            
            

            <li><a href="/docs/estimators/" class="">Estimation methods</a></li>
          
            
            

            
            

            <li><a href="/docs/lasso2/" class="">Getting started (lasso2)</a></li>
          
            
            

            
            

            <li><a href="/docs/cvlasso/" class="">Cross-validation (cvlasso)</a></li>
          
            
            

            
            

            <li><a href="/docs/rlasso/" class="">Rigorous lasso (rlasso)</a></li>
          
            
            

            
            

            <li><a href="/docs/lasso2_help/" class="">Help lasso2</a></li>
          
            
            

            
            

            <li><a href="/docs/cvlasso_help/" class="">Help cvlasso</a></li>
          
            
            

            
            

            <li><a href="/docs/rlasso_help/" class="active">Help rlasso</a></li>
          
            
            

            
            

            <li><a href="/docs/lassopack_cite/" class="">Citation</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">pdslasso</span>
        

        
        <ul>
          
            
            

            
            

            <li><a href="/docs/pdslasso/" class="">Overview</a></li>
          
            
            

            
            

            <li><a href="/docs/pdslasso_models/" class="">Models</a></li>
          
            
            

            
            

            <li><a href="/docs/pdslasso_demo/" class="">Demonstration</a></li>
          
            
            

            
            

            <li><a href="/docs/ivlasso_help/" class="">Help file</a></li>
          
            
            

            
            

            <li><a href="/docs/pdslasso_cite/" class="">Citation</a></li>
          
        </ul>
        
      </li>
    
  </ul>
</nav>
    
  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Help file: rlasso">
    
    
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Help file: rlasso
</h1>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <pre id="stlog-1" style="font-size: 12px" class="sthlp"><b>help rlasso</b>
-------------------------------------------------------------------------------------------------------------------

<b><u>Title</u></b>

    <b>rlasso</b> --  Program for lasso and sqrt-lasso estimation with data-driven penalization

<a name="stlog-1-syntax"></a><b><u>Syntax</u></b>

        <b>rlasso</b> <i>depvar</i> <i>regressors</i> [<i>weight</i>] [<b>if</b> <i>exp</i>] [<b>in</b> <i>range</i>] [ <b>,</b> <b>sqrt</b> <b>partial(</b><i>varlist</i><b>)</b> <b>pnotpen(</b><i>varlist</i><b>)</b>
              <b><u>noc</u></b><b>onstant</b> <b>fe</b> <b>noftools</b> <b><u>r</u></b><b>obust</b> <b><u>cl</u></b><b>uster(</b><i>var</i><b>)</b> <b>center</b> <b><u>xdep</u></b><b>endent</b> <b>numsim(</b><i>int</i><b>)</b> <b>prestd</b> <b><u>tol</u></b><b>opt(</b><i>real</i><b>)</b>
              <b><u>tolu</u></b><b>ps(</b><i>real</i><b>)</b> <b><u>tolz</u></b><b>ero(</b><i>real</i><b>)</b> <b><u>maxi</u></b><b>ter(</b><i>int</i><b>)</b> <b><u>maxupsi</u></b><b>ter(</b><i>int</i><b>)</b> <b>lassoups</b> <b><u>corrn</u></b><b>umber(</b><i>int</i><b>)</b> <b>lambda0(</b><i>real</i><b>)</b>
              <b><u>lalt</u></b><b>ernative</b> <b>gamma(</b><i>real</i><b>)</b> <b>gammad(</b><i>real</i><b>)</b> <b>c(</b><i>real</i><b>)</b> <b>supscore</b> <b>ssnumsim(</b><i>int</i><b>)</b> <b>testonly</b> <b>seed(</b><i>real</i><b>)</b> <b>displayall</b>
              <b>postall</b> <b>pols</b> <b><u>ver</u></b><b>bose</b> <b><u>vver</u></b><b>bose</b> ]

        Note: the <b>fe</b> option will take advantage of the <a href="#stlog-1-SG2016"><b>ftools</b></a> package (if installed) for the fixed-effects
              transform; the speed gains using this package can be large.  See help ftools or click on ssc
              install ftools to install.

    <i>General options</i>       Description
    -------------------------------------------------------------------------------------------------------------
    <b>sqrt</b>                   use sqrt-lasso (default is standard lasso)
    <b><u>noc</u></b><b>onstant</b>             suppress constant from regression (cannot be used with <b>aweights</b> or <b>pweights</b>)
    <b>fe</b>                     fixed-effects model (requires data to be <a href="http://www.stata.com/help.cgi?xtset"><b>xtset</b></a>)
    <b>noftools</b>               do not use FTOOLS package for fixed-effects transform (slower; rarely used)
    <b>partial(</b><i>varlist</i><b>)</b>       variables partialled-out prior to lasso estimation, including the constant (if
                            present); to partial-out just the constant, specify <b>partial(</b><i>_cons</i><b>)</b>
    <b>pnotpen(</b><i>varlist</i><b>)</b>       variables not penalized by lasso
    <b>robust</b>                 lasso penalty loadings account for heteroskedasticity
    <b><u>cl</u></b><b>uster(</b><i>var</i><b>)</b>           lasso penalty loadings account for clustering on variable <i>var</i>
    <b>center</b>                 center moments in heteroskedastic and cluster-robust loadings
    <b>lassoups</b>               use lasso or sqrt-lasso residuals to obtain penalty loadings (upsilon) (default is
                            post-lasso)
    <b><u>corrn</u></b><b>umber(</b><i>int</i><b>)</b>        number of high-correlation regressors used to obtain initial residuals; default=5; if
                            =0, then <i>depvar</i> is used in place of residuals
    <b>prestd</b>                 standardize data prior to estimation (default is standardize during estimation via
                            penalty loadings)
    <b>seed(</b><i>real</i><b>)</b>             set Stata's random number seed prior to <b>xdep</b> and <b>supscore</b> simulations (default=leave
                            state unchanged)

    <i>Lambda</i>                Description
    -------------------------------------------------------------------------------------------------------------
    <b><u>xdep</u></b><b>endent</b>             penalty level is estimated depending on X
    <b>numsim(</b><i>int</i><b>)</b>            number of simulations used for the X-dependent case (default=5000)
    <b>lambda0(</b><i>real</i><b>)</b>          user-specified lambda0; overrides lasso default lambda =
                            2c*sqrt(N)*invnormal(1-(gamma/log(N))/(2*p)) (sqrt-lasso default = replace 2c with c)
    <b><u>lalt</u></b><b>ernative</b>           alternative (less sharp) lambda0 = 2c*sqrt(N)*sqrt(2*log(2*p/(gamma/log(N))))
                            (sqrt-lasso = replace 2c with c)
    <b>gamma(</b><i>real</i><b>)</b>            "gamma" in numerator of fraction in lambda0 function (default = 0.1)
    <b>gammad(</b><i>real</i><b>)</b>           denominator of "gamma" fraction in lambda0 function (default = log(N); cluster-lasso
                            default = log(N_clust))
    <b>c(</b><i>real</i><b>)</b>                "c" in lambda0 function (default = 1.1)

    <i>Optimization</i>          Description
    -------------------------------------------------------------------------------------------------------------
    <b><u>tolo</u></b><b>pt(</b><i>real</i><b>)</b>           tolerance for lasso shooting algorithm (default=1e-10)
    <b><u>tolu</u></b><b>ps(</b><i>real</i><b>)</b>           tolerance for penalty loadings algorithm (default=1e-4)
    <b><u>tolz</u></b><b>ero(</b><i>real</i><b>)</b>          minimum below which coeffs are rounded down to zero (default=1e-4)
    <b><u>maxi</u></b><b>ter(</b><i>int</i><b>)</b>           maximum number of iterations for the lasso shooting algorithm (default=10k)
    <b><u>maxupsi</u></b><b>ter(</b><i>int</i><b>)</b>        maximum number of lasso-based iterations for penalty loadings (upsilon) algorithm
                            (default=2)

    <i>Sup-score test</i>        Description
    -------------------------------------------------------------------------------------------------------------
    <b>supscore</b>               report sup-score test of statistical significance
    <b>testonly</b>               report only sup-score test; do not estimate lasso regression
    <b>ssnumsim(</b><i>int</i><b>)</b>          number of simulations for sup-score test multiplier bootstrap (default=500; 0 =&gt; do
                            not simulate)

    <i>Display and post</i>      Description
    -------------------------------------------------------------------------------------------------------------
    <b>displayall</b>             display full coefficient vectors including unselected variables (default: display only
                            selected, unpenalized and partialled-out)
    <b>postall</b>                post full coefficient vector including unselected variables in e(b) (default: e(b) has
                            only selected, unpenalized and partialled-out)
    <b>pols</b>                   post OLS coefs using lasso-selected variables in e(b) (default is lasso coefs)
    <b><u>ver</u></b><b>bose</b>                show additional output
    <b><u>vver</u></b><b>bose</b>               show even more output
    <b>dots</b>                   show dots corresponding to repetitions in simulations (<b>xdep</b> and <b>supscore</b>)
    -------------------------------------------------------------------------------------------------------------

    Postestimation:

        <b>predict</b> [<a href="http://www.stata.com/help.cgi?datatypes"><i>type</i></a>] <a href="http://www.stata.com/help.cgi?newvar"><i>newvar</i></a> [<a href="http://www.stata.com/help.cgi?if"><i>if</i></a>] [<a href="http://www.stata.com/help.cgi?in"><i>in</i></a>] [ <b>,</b> <b>xb</b> <b>resid</b> <b>lasso</b> <b>ols</b> ]

    <b>predict</b> is not currently supported after fixed-effects estimation.

    <i>Options</i>               Description
    -------------------------------------------------------------------------------------------------------------
    <b>xb</b>                     generate fitted values (default)
    <b><u>r</u></b><b>esiduals</b>              generate residuals
    <b>lasso</b>                  use lasso coefficients for prediction (default is posted e(b) matrix)
    <b>ols</b>                    use OLS coefficients based on lasso-selected variables for prediction (default is
                            posted e(b) matrix)
    -------------------------------------------------------------------------------------------------------------

    Replay:

        <b>rlasso</b> [ <b>,</b> <b>displayall</b> ]

    <i>Options</i>               Description
    -------------------------------------------------------------------------------------------------------------
    <b>displayall</b>             display full coefficient vectors including unselected variables (default: display only
                            selected, unpenalized and partialled-out)
    -------------------------------------------------------------------------------------------------------------

    <b>rlasso</b> may be used with time-series or panel data, in which case the data must be tsset or xtset first; see
    help <a href="http://www.stata.com/help.cgi?tsset"><b>tsset</b></a> or <a href="http://www.stata.com/help.cgi?xtset"><b>xtset</b></a>.

    <b>aweights</b> and <b>pweights</b> are supported; see help <a href="http://www.stata.com/help.cgi?weights"><b>weights</b></a>.  <b>pweights</b> is equivalent to <b>aweights</b> + <b>robust</b>.

    All varlists may contain time-series operators or factor variables; see help <a href="http://www.stata.com/help.cgi?varlist"><b>varlist</b></a>.


<b><u>Contents</u></b>

    <a href="#stlog-1-description">Description</a>
    <a href="#stlog-1-estimation">Estimation methods</a>
    <a href="#stlog-1-loadings">Penalty loadings</a>
    <a href="#stlog-1-supscore">Sup-score test of joint significance</a>
    <a href="#stlog-1-computation">Computational notes</a>
    <a href="#stlog-1-examples">Examples of usage</a>
    <a href="#stlog-1-saved_results">Saved results</a>
    <a href="#stlog-1-references">References</a>
    <a href="#stlog-1-website">Website</a>
    <a href="#stlog-1-acknowledgements">Acknowledgements</a>
    <a href="#stlog-1-citation">Citation of lassopack</a>


<a name="stlog-1-description"></a><b><u>Description</u></b>

    <b>rlasso</b> is a routine for estimating the coefficients of a lasso or square-root lasso (sqrt-lasso) regression
    where the lasso penalization is data-dependent and where the number of regressors p may be large and possibly
    greater than the number of observations.  The lasso (Least Absolute Shrinkage and Selection Operator,
    Tibshirani <a href="#stlog-1-Tib1996"><b>1996</b></a>) is a regression method that uses regularization and the L1 norm.  <b>rlasso</b> implements a
    version of the lasso that allows for heteroskedastic and clustered errors; see Belloni et al. (<a href="#stlog-1-BCCH2012"><b>2012</b></a>, <a href="#stlog-1-BCH2013"><b>2013</b></a>,
    <a href="#stlog-1-BCH2014"><b>2014</b></a>, <a href="#stlog-1-BCHK2016"><b>2016</b></a>).

    The default estimator implemented by <b>rlasso</b> is the lasso.  An alternative that does not involve estimating
    the error variance is the square-root-lasso (sqrt-lasso) of Belloni et al. (<a href="#stlog-1-BCW2011"><b>2011</b></a>, <a href="#stlog-1-BCW2014"><b>2014</b></a>), available with the
    <b>sqrt</b> option.

    The lasso and sqrt-lasso estimators achieve sparse solutions:  of the full set of p predictors, typically
    most will have coefficients set to zero and only s&lt;&lt;p will be non-zero.  The "post-lasso" estimator is OLS
    applied to the variables with non-zero lasso or sqrt-lasso coefficients, i.e., OLS using the variables
    selected by the lasso or sqrt-lasso.  The lasso/sqrt-lasso and post-lasso coefficients are stored in <b>e(</b><i>beta</i><b>)</b>
    and <b>e(</b><i>betaOLS</i><b>)</b>, respectively.  By default, <b>rlasso</b> posts the lasso or sqrt-lasso coefficients in <b>e(</b><i>b</i><b>)</b>.  To
    post in <b>e(</b><i>b</i><b>)</b> the OLS coefficients based on lasso- or sqrt-lasso-selected variables, use the <b>pols</b> option.

<b><u>Estimation methods</u></b>

    <b>rlasso</b> solves the following problem

        min 1/N RSS + lambda/N*||Ups*beta||_1, 
        
    where

    RSS        = sum(y(i)-x(i)'beta)^2 denotes the residual sum of squares,
    beta       is a p-dimensional parameter vector,
    lambda     is the overall penalty level,
    ||.||_1    denotes the L1-norm, i.e., sum_i(abs(a[i]));
    Ups        is a p by p diagonal matrix of predictor-specific penalty loadings. Note that <b>rlasso</b> treats Ups as
                a row vector.
    N          number of observations

    If the option <b>sqrt</b> is specified, <b>rlasso</b> estimates the sqrt-lasso estimator, which is defined as the solution
    to:

        min sqrt(1/N*RSS) + lambda/N*||Ups*beta||_1. 

    Note: the above lambda differs from the definition used in parts of the lasso and elastic net literature; see
    for example the R package <i>glmnet</i> by Friedman et al. (<a href="#stlog-1-FHT2010"><b>2010</b></a>).  The objective functions here follow the format
    of Belloni et al. (<a href="#stlog-1-BCW2011"><b>2011</b></a>, <a href="#stlog-1-BCCH2012"><b>2012</b></a>).  Specifically, <i>lambda(r)=2*N*lambda(GN)</i> where <i>lambda(r)</i> is the penalty level
    used by <b>rlasso</b> and <i>lambda(GN)</i> is the penalty level used by <i>glmnet</i>.

    <b>rlasso</b> obtains the solutions to the lasso sqrt-lasso using coordinate descent algorithms.  The algorithm was
    first proposed by Fu (<a href="#stlog-1-FU1998"><b>1998</b></a>) for the lasso (then referred to as "shooting").  For further details of how the
    lasso and sqrt-lasso solutions are obtained, see <a href="http://www.stata.com/help.cgi?lasso2"><b>lasso2</b></a>.

    <b>rlasso</b> first estimates the lasso penalty level and then uses the coordinate descent algorithm to obtain the
    lasso coefficients.  For the homoskedastic case, a single penalty level lambda is applied; in the
    heteroskedastic and cluster cases, the penalty loadings vary across regressors.  The methods are discussed in
    detail in Belloni et al. (<a href="#stlog-1-BCCH2012"><b>2012</b></a>, <a href="#stlog-1-BCH2013"><b>2013</b></a>, <a href="#stlog-1-BCW2014"><b>2014</b></a>, <a href="#stlog-1-BCHK2016"><b>2016</b></a>) and are described only briefly here.  For a detailed
    discussion of an R implementation of <b>rlasso</b>, see Spindler et al. (<a href="#stlog-1-SCH2016"><b>2016</b></a>).

    For compatibility with the wider lasso literature, the documentation here uses "lambda" to refer to the
    penalty level that, combined with the possibly regressor-specific penalty loadings, is used with the
    estimation algorithm to obtain the lasso coefficients.  "lambda0" refers to the component of the overall
    lasso penalty level that does not depend on the error variance.  Note that this terminology differs from that
    in the R implementation of <b>rlasso</b> by Spindler et al. (<a href="#stlog-1-SCH2016"><b>2016</b></a>).  The vector of penalty loadings is Upsilon,
    abbreviated as Ups in the <b>rlasso</b> saved results.

    The default lambda0 for the lasso is 2c*sqrt(N)*invnormal(1-(gamma/log(N))/(2p)), where p is the number of
    penalized regressors and c and gamma are constants with default values of 1.1 and 0.1, respectively.  In the
    cluster-lasso (Belloni et al. <a href="#stlog-1-BCHK2016"><b>2016</b></a>) the default lambda0 is 2c*sqrt(N)*invnormal(1-(gamma/log(N_clust))/(2p)),
    where N_clust is the number of clusters (saved in <b>e(</b><i>N_clust</i><b>)</b>).  The default lambda0s for the sqrt-lasso are
    the same except replace 2c with c.  The constant c&gt;1.0 is a slack parameter; gamma controls the confidence
    level.  The alternative formula lambda0 = 2c*sqrt(N)*sqrt(2*log(2p/(gamma/log(N)))) is available with the
    <b>lalt</b> option.  The constants c and gamma can be set using the <b>c(</b><i>real</i><b>)</b> and <b>gamma(</b><i>real</i><b>)</b> options.  The
    denominator of the gamma fraction can be set with the <b>gammad(</b><i>real</i><b>)</b> option; some papers in the literature set
    the denominator to 1, i.e., <b>gammad(</b><i>1</i><b>)</b> and lambda0=2c*sqrt(N)*invnormal(1-gamma/(2p)).  The <b>xdep</b> option is
    another alternative that implements an "X-dependent" penalty level lambda0; see Belloni and Chernozhukov
    (<a href="#stlog-1-BC2011"><b>2011</b></a>) and Belloni et al. (<a href="#stlog-1-BCH2013"><b>2013</b></a>) for discussion.  The <b>c(</b><i>real</i><b>)</b> option is ignored when <b>xdep</b> is specified.

    The default lambda for the lasso is lambda0*rmse, where rmse is an estimate of the standard deviation of the
    error variance.  The sqrt-lasso differs from the standard lasso in that the penalty term lambda is pivotal in
    the homoskedastic case and does not depend on the error variance.  The default for the sqrt-lasso is
    lambda=lambda0=c*sqrt(N)*invnormal(1-(gamma/log(N))/(2*p)) (note the absence of the factor of "2" vs. the
    lasso lambda).

<a name="stlog-1-loadings"></a><b><u>Penalty loadings</u></b>

    As is standard in the lasso literature, regressors are standardized to have unit variance.  By default,
    standardization is achieved by incorporating the standard deviations of the regressors into the penalty
    loadings.  In the default homoskedastic case, the penalty loadings are the vector of standard deviations of
    the regressors.  The normalized penalty loadings are the penalty loadings normalized by the SDs of the
    regressors.  In the homoskedastic case the normalized penalty loadings are a vector of 1s.  <b>rlasso</b> saves the
    vector of penalty loadings, the vector of normalized penalty loadings, and the vector of SDs of the
    regressors X in <b>e(</b>.<b>)</b> macros.

    Penalty loadings are constructed after the partialling-out of unpenalized regressors and/or the FE
    (fixed-effects) transformation, if applicable.  A alternative to partialling-out unpenalized regressors with
    the <b>partial(</b><i>varlist</i><b>)</b> option is to give them penalty loadings of zero with the <b>pnotpen(</b><i>varlist</i><b>)</b> option.  By
    the Frisch-Waugh-Lovell Theorem for the lasso (Yamada <a href="#stlog-1-Yam2017"><b>2017</b></a>), the estimated lasso coefficients are the same in
    theory (but see <a href="#stlog-1-notpen"><b>below</b></a>) whether the unpenalized regressors are partialled-out or given zero penalty loadings,
    so long as the same penalty loadings are used for the penalized regressors in both cases.  Note that the
    calculation of the penalty loadings in both the <b>partial(</b>.<b>)</b> and <b>pnotpen(</b>.<b>)</b> cases involves adjustments for the
    partialled-out variables.  This is different from the <b>lasso2</b> handling of unpenalized variables specified in
    the <b>lasso2</b> option <b>notpen(</b>.<b>)</b>, where no such adjustment of the penalty loadings is made (and is why the two
    no-penalization options are named differently).

    Regressor-specific penalty loadings for the heteroskedastic and clustered cases are derived following the
    methods described in Belloni et al. (<a href="#stlog-1-BCCH2012"><b>2012</b></a>, <a href="#stlog-1-BCH2013"><b>2013</b></a>, <a href="#stlog-1-BCH2014"><b>2014</b></a>, <a href="#stlog-1-BCW2015"><b>2015</b></a>, <a href="#stlog-1-BCHK2016"><b>2016</b></a>).  The penalty loadings for the
    heteroskedastic-robust case have elements of the form sqrt[avg(x^2e^2)]/sqrt[avg(e^2)] where x is a
    (demeaned) regressor, e is the residual, and sqrt[avg(e^2)] is the root mean squared error; the normalized
    penalty loadings have elements sqrt[avg(x^2e^2)]/(sqrt[avg(x^2)]sqrt[avg(e^2)]) where the sqrt(avg(x^2) in
    the denominator is SD(x), the standard deviation of x.  This corresponds to the presentation of penalty
    loadings in Belloni et al. (<a href="#stlog-1-BCW2014"><b>2014</b></a>; see Algorithm 1 but note that in their presentation, the predictors x are
    assumed already to be standardized).  NB: in the presentation we use here, the penalty loadings for the lasso
    and sqrt-lasso are the same; what differs is the overall penalty term lambda.

    The cluster-robust case is similar to the heteroskedastic case except that numerator sqrt[avg(x^2e^2)] in the
    heteroskedastic case is replaced by sqrt[avg(u_i^2)], where (using the notation of the Stata manual's
    discussion of the _robust command) u_i is the sum of x_ij*e_ij over the j members of cluster i; see Belloni
    et al. (<a href="#stlog-1-BCHK2016"><b>2016</b></a>).  Again in the presentation used here, the cluster-lasso and cluster-sqrt-lasso penalty
    loadings are the same.  The unit vector is again the benchmark for the standardized penalty loadings.  NB:
    also following <a href="http://www.stata.com/help.cgi?_robust"><b>_robust</b></a>, the denominator of avg(u_i^2) and Tbar is (N_clust-1).

    The <b>center</b> option centers the x_ij*e_ij terms (or the cluster-lasso case, the u_i terms) prior to calculating
    the penalty loadings.

<a name="stlog-1-supscore"></a><b><u>Sup-score test of joint significance</u></b>

    <b>rlasso</b> with the <b>supscore</b> option reports a test of the null hypothesis H0: beta_1 = ... = beta_p = 0.  i.e., a
    test of the joint significance of the regressors (or, alternatively, a test that H0: s=0; of the full set of
    p regressors, none is in the true model).  The test follows Chernozhukov et al. (<a href="#stlog-1-CCK2013"><b>2013</b></a>, Appendix M); see also
    Belloni et al. (<a href="#stlog-1-BCCH2012"><b>2012</b></a>, <a href="#stlog-1-BCH2013"><b>2013</b></a>).  (The variables are assumed to be rescaled to be centered and with unit
    variance.)

    If the null hypothesis is correct and the rest of the model is well-specified (including the assumption that
    the regressors are orthogonal to the disturbance e), then E(e*x_j) = E((y-beta_0)*x_j) = 0, j=1...p where
    beta_0 is the intercept.  The sup-score statistic is
    S=N*max_j(abs(avg((y-b_0)*x_j))/(sqrt(avg(((y-b_0)*x_j)^2)))), where:  (a) the numerator
    abs(avg((y-b_0)*x_j)) is the absolute value of the average score for regressor x_j and b_0 is sample mean of
    y; (b) the denominator sqrt(avg(((y-b_0)*x_j)^2)) is the sample standard deviation of the score; (c) the
    statistic is N times the maximum across the p regressors of the ratio of (a) to (b).

    The p-value for the sup-score test is obtained by a multiplier bootstrap procedure simulating the statistic
    W, defined as W=N*max_j(abs(avg((y-b_0)*x_j*u))/(sqrt(avg(((y-b_0)*x_j)^2)))) where u is an iid standard
    normal variate independent of the data.  The <b>ssnumsim(</b><i>int</i><b>)</b> option controls the number of simulated draws
    (default=500); <b>ssnumsim(</b><i>0</i><b>)</b> requests that the sup-score statistic is reported without a simulation-based
    p-value.  <b>rlasso</b> also reports a conservative critical value (asymptotic bound) as per Belloni et al. (<a href="#stlog-1-BCCH2012"><b>2012</b></a>,
    <a href="#stlog-1-BCCH2013"><b>2013</b></a>), defined as c*sqrt(N)*invnormal(1-gamma/(2p)) where gamma is the same gamma as in the penalty level
    lambda, set by the <b>gamma(</b><i>real</i><b>)</b> option (default=0.10).  Note that the critical value is identical to the
    sqrt-lasso lambda with option <b>gammad(</b><i>1</i><b>)</b>.

<a name="stlog-1-computation"></a><b><u>Computational notes</u></b>

    A computational alternative to the default of standardizing "on the fly" (i.e., incorporating the
    standardization into the lasso penalty loadings) is to standardize all variables to have unit variance prior
    to computing the lasso coefficients.  This can be done using the <b>prestd</b> option.  The results are equivalent
    in theory.  The <b>prestd</b> option can lead to improved numerical precision or more stable results in the case of
    difficult problems; the cost is (a typically small) computation time required to standardize the data.

<a name="stlog-1-notpen"></a>    Either the <b>partial(</b><i>varlist</i><b>)</b> option or the <b>pnotpen(</b><i>varlist</i><b>)</b> option can be used for variables that should not
    be penalized by the lasso.  The options are equivalent in theory (see above), but numerical results can
    differ in practice because of the different calculation methods used.  Partialling-out variables can lead to
    improved numerical precision or more stable results in the case of difficult problems vs. specifying the
    variables as unpenalized, but may be slower in terms of computation time.

    By default the constant (if present) is not penalized if there are no regressors being partialled out; this
    is equivalent to mean-centering prior to estimation.  The exception to this is if <b>aweights</b> or <b>aweights</b> are
    specified, in which case the constant is partialled-out.  The <b>partial(</b><i>varlist</i><b>)</b> option will automatically also
    partial out the constant (if present); to partial out just the constant, specify <b>partial(</b><i>_cons</i><b>)</b>.  Both
    <b>partial(</b>.<b>)</b> and <b>fe</b> mean-center the data; the <b>nocons</b> option is redundant in this case and may not be specified
    with these options.  If the <b>nocons</b> option is specified an intercept is not included in the model, but the
    estimated penalty loadings (see <a href="#stlog-1-loadings">above</a>) are still estimated using mean-centered regressors.

    The <b>prestd</b> and <b>pnotpen(</b><i>varlist</i><b>)</b> vs. <b>partial(</b><i>varlist</i><b>)</b> options can be used as simple checks for numerical
    stability by comparing results that should be equivalent in theory.

    The <b>fe</b> fixed-effects option is equivalent to (but computationally faster and more accurate than) specifying
    unpenalized panel-specific dummies.  The fixed-effects ("within") transformation also removes the constant as
    well as the fixed effects.  The panel variable used by the <b>fe</b> option is the panel variable set by <a href="http://www.stata.com/help.cgi?xtset"><b>xtset</b></a>.  To
    use weights with fixed effects, the ftools must be installed.

<a name="stlog-1-misc"></a><b><u>Miscellaneous</u></b>

    By default <b>rlasso</b> reports only the set of selected variables and their lasso and post-lasso coefficients; the
    omitted coefficients are not reported in the regression output.  The <b>postall</b> and <b>displayall</b> options allow the
    full coefficient vector (with coefficients of unselected variables set to zero) to be either posted in <b>e(</b><i>b</i><b>)</b>
    or displayed as output.

    <b>rlasso</b>, like the lasso in general, accommodates possibly perfectly-collinear sets of regressors.  Stata's
    <a href="http://www.stata.com/help.cgi?fvvarlist"><b>factor variables</b></a> are supported by <b>rlasso</b> (as well as by <a href="http://www.stata.com/help.cgi?lasso2"><b>lasso2</b></a>).  Users therefore have the option of
    specifying as regressors one or more complete sets of factor variables or interactions with no base levels
    using the <i>ibn</i> prefix.  This can be interpreted as allowing <b>rlasso</b> to choose the members of the base category.

    The choice of whether to use <b>partial(</b><i>varlist</i><b>)</b> or <b>pnotpen(</b><i>varlist</i><b>)</b> will depend on the circumstances faced by
    the user.  The <b>partial(</b><i>varlist</i><b>)</b> option can be helpful in dealing with data that have scaling problems or
    collinearity issues; in these cases it can be more accurate and/or achieve convergence faster than the
    <b>pnotpen(</b><i>varlist</i><b>)</b> option.  The <b>pnotpen(</b><i>varlist</i><b>)</b> option will sometimes be faster because it avoids using the
    pre-estimation transformation employed by <b>partial(</b><i>varlist</i><b>)</b>.  The two options can be used simultaneously (but
    not for the same variables).

    The treatment of standardization, penalization and partialling-out in <b>rlasso</b> differs from that of <b>lasso2</b>.  In
    the <b>rlasso</b> treatment, standardization incorporates the partialling-out of regressors listed in the
    <b>pnotpen(</b><i>varlist</i><b>)</b> list as well as those in the <b>partial(</b><i>varlist</i><b>)</b> list.  This is in order to maintain the
    equivalence of the lasso estimator irrespective of which option is used for unpenalized variables (see the
    discussion of the Frisch-Waugh-Lovell Theorem for the lasso above).  In the <b>lasso2</b> treatment, standardization
    takes place after the partialling-out of only the regressors listed in the <b>notpen(</b><i>varlist</i><b>)</b> option.  In other
    words, <b>rlasso</b> adjusts the penalty loadings for any unpenalized variables; <b>lasso2</b> does not.  For further
    details, see <a href="http://www.stata.com/help.cgi?lasso2"><b>lasso2</b></a>.

    Belloni et al. (<a href="#stlog-1-BCW2014"><b>2014</b></a>) recommend using gamma=0.05 (instead of the <b>rlasso</b> default 0.1)) with the sqrt-lasso.

    The initial overhead for fixed-effects estimation and/or partialling out and/or pre-estimation
    standardization (creating temporary variables and then transforming the data) can be noticable for large
    datasets.  For problems that involve looping over data, users may wish to first transform the data by hand.

    If a small number of correlations is set using the <b>corrnum(</b><i>int</i><b>)</b> option, users may want to increase the number
    of penalty loadings iterations from the default of 2 to something higher using the <b>maxupsiter(</b><i>int</i><b>)</b> option.

    The sup-score p-value is obtained by simulation, which can be time-consuming for large datasets.  To skip
    this and use only the conservative (asymptotic bound) critical value, set the number of simulations to zero
    with the <b>ssnumsim(</b><i>0</i><b>)</b> option.

<a name="stlog-1-examples"></a><b><u>Examples using prostate cancer data from Hastie et al. (</u></b><a href="#stlog-1-HTF2009"><b><u>2009</u></b></a><b><u>)</u></b>

    Load prostate cancer data.
        . clear
        . insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data, tab

    Estimate lasso using data-driven lambda penalty; default homoskedasticity case.
        . rlasso lpsa lcavol lweight age lbph svi lcp gleason pgg45

    Use square-root lasso instead.
        . rlasso lpsa lcavol lweight age lbph svi lcp gleason pgg45, sqrt

    Illustrate relationships between lambda, lambda0 and penalty loadings:

    Basic usage: homoskedastic case, lasso
        . rlasso lpsa lcavol lweight age lbph svi lcp gleason pgg45
    lambda=lambda0*SD is lasso penalty; incorporates the estimate of the error variance
    default lambda0 is 2c*sqrt(N)*invnormal(1-(gamma/log(N))/(2*p))
        . di e(lambda)
        . di e(lambda0)
    In the homoskedastic case, penalty loadings are the vector of SDs of penalized regressors
        . mat list e(eUps)
    ...and the standardized penalty loadings are a vector of 1s.
        . mat list e(sUps)

    Heteroskedastic case, lasso
        . rlasso lpsa lcavol lweight age lbph svi lcp gleason pgg45, robust
    lambda and lambda0 are the same as for the homoskedastic case
        . di e(lambda)
        . di e(lambda0)
    Penalty loadings account for heteroskedasticity as well as incorporating SD(x)
        . mat list e(eUps)
    ...and the standardized penalty loadings are not a vector of 1s.
        . mat list e(sUps)

    Homoskedastic case, sqrt-lasso
        . rlasso lpsa lcavol lweight age lbph svi lcp gleason pgg45, sqrt
    with the sqrt-lasso, the default lambda=lambda0=c*sqrt(N)*invnormal(1-(gamma/log(N))/(2*p));
    note the difference by a factor of 2 vs. the standard lasso lambda0
        . di e(lambda)
        . di e(lambda0)

    <b>rlasso</b> vs. <b>lasso2</b> (if installed)
        . rlasso lpsa lcavol lweight age lbph svi lcp gleason pgg45
    lambda=lambda0*SD is lasso penalty; incorporates the estimate of the error variance
    default lambda0 is 2c*sqrt(N)*invnormal(1-(gamma/log(N))/(2*p))
        . di %8.5f e(lambda)
    Replicate <b>rlasso</b> estimates using <b>rlasso</b> lambda and <b>lasso2</b>
        . lasso2 lpsa lcavol lweight age lbph svi lcp gleason pgg45, lambda(44.34953)

<b><u>Examples using data from Acemoglu-Johnson-Robinson (</u></b><a href="#stlog-1-AJR2001"><b><u>2001</u></b></a><b><u>)</u></b>

    Load and reorder AJR data for Table 6 and Table 8 (datasets need to be in current directory).
        . clear
        . (click to download maketable6.zip from economics.mit.edu)
        . unzipfile maketable6
        . (click to download maketable8.zip from economics.mit.edu)
        . unzipfile maketable8
        . use maketable6
        . merge 1:1 shortnam using maketable8
        . keep if baseco==1
        . order shortnam logpgp95 avexpr lat_abst logem4 edes1975 avelf, first
        . order indtime euro1900 democ1 cons1 democ00a cons00a, last

    Basic usage:
        . rlasso logpgp95 lat_abst edes1975 avelf temp* humid* steplow-oilres

    Heteroskedastic-robust penalty loadings:
        . rlasso logpgp95 lat_abst edes1975 avelf temp* humid* steplow-oilres, robust

    Partialling-out vs. non-penalization:
        . rlasso logpgp95 lat_abst edes1975 avelf temp* humid* steplow-oilres, partial(lat_abst)
        . rlasso logpgp95 lat_abst edes1975 avelf temp* humid* steplow-oilres, pnotpen(lat_abst)

    Request sup-score test (H0: all betas=0):
        . rlasso logpgp95 lat_abst edes1975 avelf temp* humid* steplow-oilres, supscore

<b><u>Examples using data from Angrist-Krueger (</u></b><a href="#stlog-1-AK1991"><b><u>1991</u></b></a><b><u>)</u></b>

    Load AK data and rename variables (dataset needs to be in current directory).  NB: this is a large dataset
    (330k observations) and estimations may take some time to run on some installations.
        . clear
        . (click to download asciiqob.zip from economics.mit.edu)
        . unzipfile asciiqob.zip
        . infix lnwage 1-9 educ 10-20 yob 21-31 qob 32-42 pob 43-53 using asciiqob.txt
        . xtset pob

    State (place of birth) fixed effects; regressors are year of birth, quarter of birth and QOBxYOB.
        . rlasso educ i.yob# #i.qob, fe

    As above but explicit penalized state dummies and all categories (no base category) for all factor vars.
    Note that the (unpenalized) constant is reported.
        . rlasso educ ibn.yob# #ibn.qob ibn.pob

    State fixed effects; regressors are YOB, QOB and QOBxYOB; cluster on state.
        . rlasso educ i.yob# #i.qob, fe cluster(pob)

<b><u>Example using data from Belloni et al. (</u></b><a href="#stlog-1-BCH2015"><b><u>2015</u></b></a><b><u>)</u></b>

    Load dataset on eminent domain (available at journal website).
        . clear
        . import excel using CSExampleData.xlsx, first

    Settings used in Belloni et al. (<a href="#stlog-1-BCH2015"><b>2015</b></a>) - results as in text discussion (p=147):
        . rlasso NumProCase Z* BA BL DF, robust lalt corrnum(0) maxupsiter(100)
        . di e(p)

    Settings used in Belloni et al. (<a href="#stlog-1-BCH2015"><b>2015</b></a>) - results as in journal replication file (p=144):
        . rlasso NumProCase Z*, robust lalt corrnum(0) maxupsiter(100)
        . di e(p)


<a name="stlog-1-saved_results"></a><b><u>Saved results</u></b>

    <b>rlasso</b> saves the following in <b>e()</b>:

    scalars       
      <b>e(N)</b>               sample size
      <b>e(N_clust)</b>         number of clusters in cluster-robust estimation
      <b>e(N_g)</b>             number of groups in fixed-effects model
      <b>e(p)</b>               number of penalized regressors in model
      <b>e(s)</b>               number of selected regressors
      <b>e(s0)</b>              number of selected and unpenalized regressors including constant (if present)
      <b>e(lambda0)</b>         penalty level excluding rmse (default = 2c*sqrt(N)*invnormal(1-(gamma/log(N))/(2*p)))
      <b>e(lambda)</b>          lasso: penalty level including rmse (=lambda0*rmse); sqrt-lasso: lambda=lambda0
      <b>e(slambda)</b>         standardized lambda; equiv to lambda used on standardized data; lasso:
                           slambda=lambda/SD(depvar); sqrt-lasso: slambda=lambda0
      <b>e(c)</b>               parameter in penalty level lambda
      <b>e(gamma)</b>           parameter in penalty level lambda
      <b>e(gammad)</b>          parameter in penalty level lambda
      <b>e(niter)</b>           number of iterations for shooting algorithm
      <b>e(maxiter)</b>         max number of iterations for shooting algorithm
      <b>e(nupsiter)</b>        number of iterations for loadings algorithm
      <b>e(maxupsiter)</b>      max iterations for loadings algorithm
      <b>e(rmse)</b>            rmse using lasso resduals
      <b>e(rmseOLS)</b>         rmse using post-lasso residuals
      <b>e(cons)</b>            =1 if constant in model, =0 otherwise
      <b>e(fe)</b>              =1 if fixed-effects model, =0 otherwise
      <b>e(center)</b>          =1 if moments have been centered
      <b>e(supscore)</b>        sup-score statistic
      <b>e(supscore_p)</b>      sup-score p-value
      <b>e(supscore_cv)</b>     sup-score critical value (asymptotic bound)

    macros        
      <b>e(cmd)</b>             rlasso
      <b>e(depvar)</b>          name of dependent variable
      <b>e(varX)</b>            all regressors
      <b>e(varXmodel)</b>       penalized regressors
      <b>e(pnotpen)</b>         unpenalized regressors
      <b>e(partial)</b>         partialled-out regressors
      <b>e(selected)</b>        selected and penalized regressors
      <b>e(selected0)</b>       all selected regressors including unpenalized and constant (if present)
      <b>e(method)</b>          lasso or sqrt-lasso
      <b>e(estimator)</b>       lasso, sqrt-lasso or post-lasso posted in e(b)
      <b>e(robust)</b>          heteroskedastic-robust penalty loadings
      <b>e(clustvar)</b>        variable defining clusters for cluster-robust penalty loadings
      <b>e(ivar)</b>            variable defining groups for fixed-effects model

    matrices      
      <b>e(b)</b>               posted coefficient vector
      <b>e(beta)</b>            lasso or sqrt-lasso coefficient vector
      <b>e(betaOLS)</b>         post-lasso coefficient vector
      <b>e(betaAll)</b>         full lasso or sqrt-lasso coefficient vector including omitted, factor base variables,
                           etc.
      <b>e(betaAllOLS)</b>      full post-lasso coefficient vector including omitted, factor base variables, etc.
      <b>e(eUps)</b>            estimated penalty loadings
      <b>e(sUps)</b>            standardized penalty loadings (vector of 1s in homoskedastic case

    functions     
      <b>e(sample)</b>          estimation sample


<a name="stlog-1-references"></a><b><u>References</u></b>

<a name="stlog-1-AJR2001"></a>    Acemoglu, D., Johnson, S. and Robinson, J.A. 2001.  The colonial origins of comparative development: An
        empirical investigation.  <i>American Economic Review</i>, 91(5):1369-1401.
        https://economics.mit.edu/files/4123

<a name="stlog-1-AK1991"></a>    Angrist, J. and Kruger, A. 1991.  Does compulsory school attendance affect schooling and earnings?  <i>Quarterly</i>
        <i>Journal of Economics</i> 106(4):979-1014.  http://www.jstor.org/stable/2937954

<a name="stlog-1-BC2011"></a>    Belloni, A. and Chernozhukov, V. 2011.  High-dimensional sparse econometric models: An introduction.  In
        Alquier, P., Gautier E., and Stoltz, G. (eds.), Inverse problems and high-dimensional estimation.
        Lecture notes in statistics, vol. 203.  Springer, Berlin, Heidelberg.
        https://arxiv.org/pdf/1106.5242.pdf

<a name="stlog-1-BCW2011"></a>    Belloni, A., Chernozhukov, V. and Wang, L. 2011.  Square-root lasso: Pivotal recovery of sparse signals via
        conic programming.  <i>Biometrika</i> 98:791-806.  https://doi.org/10.1214/14-AOS1204

<a name="stlog-1-BCCH2012"></a>    Belloni, A., Chen, D., Chernozhukov, V. and Hansen, C. 2012.  Sparse models and methods for optimal
        instruments with an application to eminent domain.  <i>Econometrica</i> 80(6):2369-2429.  
        http://onlinelibrary.wiley.com/doi/10.3982/ECTA9626/abstract

<a name="stlog-1-BCH2013"></a>    Belloni, A., Chernozhukov, V. and Hansen, C. 2013.  Inference for high-dimensional sparse econometric models.
        In <i>Advances in Economics and Econometrics: 10th World Congress</i>, Vol. 3: Econometrics, Cambridge
        University Press: Cambridge, 245-295.  http://arxiv.org/abs/1201.0220

<a name="stlog-1-BCH2014"></a>    Belloni, A., Chernozhukov, V. and Hansen, C. 2014.  Inference on treatment effects after selection among
        high-dimensional controls.  <i>Review of Economic Studies</i> 81:608-650.  https://doi.org/10.1093/restud/rdt044

<a name="stlog-1-BCH2015"></a>    Belloni, A., Chernozhukov, V. and Hansen, C. 2015.  High-dimensional methods and inference on structural and
        treatment effects.  <i>Journal of Economic Perspectives</i> 28(2):29-50.  
        http://www.aeaweb.org/articles.php?doi=10.1257/jep.28.2.29

<a name="stlog-1-BCHK2016"></a>    Belloni, A., Chernozhukov, V., Hansen, C. and Kozbur, D. 2016.  Inference in high dimensional panel models
        with an application to gun control.  <i>Journal of Business and Economic Statistics</i> 34(4):590-605.  
        http://amstat.tandfonline.com/doi/full/10.1080/07350015.2015.1102733

<a name="stlog-1-BCW2014"></a>    Belloni, A., Chernozhukov, V. and Wang, L. 2014.  Pivotal estimation via square-root-lasso in nonparametric
        regression.  <i>Annals of Statistics</i> 42(2):757-788.  https://doi.org/10.1214/14-AOS1204

<a name="stlog-1-CCK2013"></a>    Chernozhukov, V., Chetverikov, D. and Kato, K. 2013.  Gaussian approximations and multiplier bootstrap for
        maxima of sums of high-dimensional random vectors.  <i>Annals of Statistics</i> 41(6):2786-2819.  
        https://projecteuclid.org/euclid.aos/1387313390

<a name="stlog-1-SG2016"></a>    Correia, S. 2016.  FTOOLS: Stata module to provide alternatives to common Stata commands optimized for large
        datasets.  https://ideas.repec.org/c/boc/bocode/s458213.html

<a name="stlog-1-FHT2010"></a>    Friedman, J., Hastie, T., &amp; Tibshirani, R. (2010).  Regularization Paths for Generalized Linear Models via
        Coordinate Descent.  <i>Journal of Statistical Software</i> 33(1), 1\9622.  
        https://doi.org/10.18637/jss.v033.i01

<a name="stlog-1-FU1998"></a>    Fu, W.J.  1998.  Penalized regressions: The bridge versus the lasso.  <i>Journal of Computational and Graphical</i>
        <i>Statistics</i> 7(3):397-416.  http://www.tandfonline.com/doi/abs/10.1080/10618600.1998.10474784

<a name="stlog-1-HTF2009"></a>    Hastie, T., Tibshirani, R. and Friedman, J. 2009.  <i>The elements of statistical learning</i> (2nd ed.).  New York:
        Springer-Verlag.  https://web.stanford.edu/~hastie/ElemStatLearn/

<a name="stlog-1-SCH2016"></a>    Spindler, M., Chernozhukov, V. and Hansen, C. 2016.  High-dimensional metrics.
        https://cran.r-project.org/package=hdm.

<a name="stlog-1-Tib1996"></a>    Tibshirani, R. 1996.  Regression shrinkage and selection via the lasso.  <i>Journal of the Royal Statistical</i>
        <i>Society. Series B (Methodological)</i> 58(1):267-288.  https://doi.org/10.2307/2346178

<a name="stlog-1-Yam2017"></a>    Yamada, H. 2017.  The Frisch-Waugh-Lovell Theorem for the lasso and the ridge regression.  <i>Communications in</i>
        <i>Statistics - Theory and Methods</i> 46(21):10897-10902.  http://dx.doi.org/10.1080/03610926.2016.1252403

<a name="stlog-1-website"></a><b><u>Website</u></b>

    Please check our website https://statalasso.github.io/ for more information.

<a name="stlog-1-acknowledgements"></a><b><u>Acknowledgements</u></b>

    Thanks to Alexandre Belloni for providing Matlab code for the square-root-lasso and to Sergio Correia for
    advice on the use of the FTOOLS package.


<a name="stlog-1-citation"></a><b><u>Citation of rlasso</u></b>

    <b>rlasso</b> is not an official Stata command. It is a free contribution to the research community, like a paper.
    Please cite it as such:

    Ahrens, A., Hansen, C.B., Schaffer, M.E. 2018.  rlasso: Progam for lasso and sqrt-lasso estimation with
        data-driven penalization.  http://ideas.repec.org/c/boc/bocode/s458458.html


<b><u>Authors</u></b>

        Achim Ahrens, Economic and Social Research Institute, Ireland
        achim.ahrens@esri.ie
        
        Christian B. Hansen, University of Chicago, USA
        Christian.Hansen@chicagobooth.edu

        Mark E Schaffer, Heriot-Watt University, UK
        m.e.schaffer@hw.ac.uk


<b><u>Also see</u></b>

       Help:  <a href="http://www.stata.com/help.cgi?lasso2"><b>lasso2</b></a>, <a href="http://www.stata.com/help.cgi?cvlasso"><b>cvlasso</b></a>, <a href="http://www.stata.com/help.cgi?pdslasso">pdslasso</a>, <a href="http://www.stata.com/help.cgi?ivlasso">ivlasso</a> (if installed)
</pre>

        
      </section>

      <footer class="page__meta">
        
        


        
      </footer>

      

      
    </div>

    
  </article>

  
  
</div>
    </div>

    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
    
    
    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2018 Achim Ahrens. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.0.9/js/all.js"></script>








  </body>
</html>