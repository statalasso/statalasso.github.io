<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DDML on Stata ML Page</title>
    <link>https://statalasso.github.io/docs/ddml/</link>
    <description>Recent content in DDML on Stata ML Page</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://statalasso.github.io/docs/ddml/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Model overview</title>
      <link>https://statalasso.github.io/docs/ddml/models/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://statalasso.github.io/docs/ddml/models/</guid>
      <description>Supported models # Throughout we use \(Y\) to denote the outcome variable, \(X\) to denote confounders, \(Z\) to denote instrumental variable(s), and \(D\) to denote the treatment variable(s) of interest.
For a full discussion, please check our working paper.
Partial linear model [partial] # \[ Y = a.D &amp;#43; g(X) &amp;#43; U \\ D = m(X) &amp;#43; V \quad\quad~~\] where the aim is to estimate \(a\) while flexibly controlling for \(X\) .</description>
    </item>
    
    <item>
      <title>Algorithm</title>
      <link>https://statalasso.github.io/docs/ddml/crossfit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://statalasso.github.io/docs/ddml/crossfit/</guid>
      <description>DDML Algorithm # DDML estimators proceed in two stages:
Cross-fitting to estimate conditional expectation functions. Second stage estimation based on Neyman orthogonal scores. Chernozhukov et al. (2018) show that cross-fitting ensures that we can leverage a large class of machine learners for causal inference &amp;ndash; including popular machine learners such as random forests or gradient boosting. Cross-fitting ensures independence between the estimation error from the first step and the regression residual in the second stage.</description>
    </item>
    
    <item>
      <title>Partial Linear Model (PLM)</title>
      <link>https://statalasso.github.io/docs/ddml/plm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://statalasso.github.io/docs/ddml/plm/</guid>
      <description>Partially Linear Model # Preparations # We load the data, define global macros and set the seed.
. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear . global Y net_tfa . global D e401 . global X tw age inc fsize educ db marr twoearn pira hown . set seed 42 Step 1: Initialize DDML model # We next initialize the ddml estimation and select the model. partial refers to the partially linear model. The model will be stored on a Mata object with the default name &amp;ldquo;m0&amp;rdquo; unless otherwise specified using the mname(name) option.</description>
    </item>
    
    <item>
      <title>PLM &amp; Stacking</title>
      <link>https://statalasso.github.io/docs/ddml/plm2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://statalasso.github.io/docs/ddml/plm2/</guid>
      <description>Partially linear model with Stacking # Stacking regression is a simple and powerful method for combining predictions from multiple learners. It is available in Stata via the pystacked package (see here). Below is an example with the partially linear model, but it can be used with any model supported by ddml.
Step 1: Initialization # Preparation: use the data and globals as above. Use the name m1 for this new estimation, to distinguish it from the previous example that uses the default name m0.</description>
    </item>
    
    <item>
      <title>Interactive</title>
      <link>https://statalasso.github.io/docs/ddml/interactive/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://statalasso.github.io/docs/ddml/interactive/</guid>
      <description>Interactive Model # Preparations: we load the data, define global macros and set the seed.
. webuse cattaneo2, clear (Excerpt from Cattaneo (2010) Journal of Econometrics 155: 138â€“154) . global Y bweight . global D mbsmoke . global X mage prenatal1 mmarried fbaby mage medu . set seed 42 Step 1: Initialization # We use 5 folds and 5 resamplings; that is, we estimate the model 5 times using randomly chosen folds.</description>
    </item>
    
    <item>
      <title>Partial Linear IV</title>
      <link>https://statalasso.github.io/docs/ddml/iv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://statalasso.github.io/docs/ddml/iv/</guid>
      <description>Partial Linear IV Model # Preparations # We load the data, define global macros and set the seed.
. use https://statalasso.github.io/dta/AJR.dta, clear . global Y logpgp95 . global D avexpr . global Z logem4 . global X lat_abst edes1975 avelf temp* humid* steplow-oilres . set seed 42 Step 1: Initialization # Since the data set is very small, we consider 30 cross-fitting folds.
. ddml init iv, kfolds(30) Step 2: Adding learners # The partially linear IV model has three conditional expectations: \(E[Y|X]\) , \(E[D|X]\) and \(E[Z|X]\) .</description>
    </item>
    
    <item>
      <title>Flexible IV</title>
      <link>https://statalasso.github.io/docs/ddml/ivhd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://statalasso.github.io/docs/ddml/ivhd/</guid>
      <description>Flexible Partially Linear IV Model # Preparations # We load the data, define global macros and set the seed.
. use https://statalasso.github.io/dta/BLP_CHS.dta, clear . global Y y . global D price . global X hpwt air mpd space . global Z Zbase* . set seed 42 Step 1: Initialization # We initialize the model.
. ddml init ivhd Step 2: Add learners # We add learners for \(E[Y|X]\) in the usual way.</description>
    </item>
    
    <item>
      <title>Interactive IV</title>
      <link>https://statalasso.github.io/docs/ddml/interactiveiv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://statalasso.github.io/docs/ddml/interactiveiv/</guid>
      <description>Interactive IV Model # Preparations # We load the data, define global macros and set the seed.
. use http://fmwww.bc.edu/repec/bocode/j/jtpa.dta,clear . global Y earnings . global D training . global Z assignmt . global X sex age married black hispanic . set seed 42 Step 1: Initialization # We initialize the model.
. ddml init interactiveiv, kfolds(5) Step 2: Add learners # We use stacking (implemented in pystacked) with two base learners for each reduced form equation.</description>
    </item>
    
    <item>
      <title>ddml help file</title>
      <link>https://statalasso.github.io/docs/ddml/help/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://statalasso.github.io/docs/ddml/help/</guid>
      <description>----------------------------------------------------------------------------------------------------------------------------------------------------------------- help ddml v1.2 ----------------------------------------------------------------------------------------------------------------------------------------------------------------- Title ddml -- Stata package for Double Debiased Machine Learning ddml implements algorithms for causal inference aided by supervised machine learning as proposed in Double/debiased machine learning for treatment and structural parameters (Econometrics Journal, 2018). Five different models are supported, allowing for binary or continous treatment variables and endogeneity, high-dimensional controls and/or instrumental variables. ddml supports a variety of different ML programs, including but not limited to lassopack and pystacked.</description>
    </item>
    
    <item>
      <title>qddml help file</title>
      <link>https://statalasso.github.io/docs/ddml/help_qddml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://statalasso.github.io/docs/ddml/help_qddml/</guid>
      <description>----------------------------------------------------------------------------------------------------------------------------------------------------------------- help ddml v1.2 ----------------------------------------------------------------------------------------------------------------------------------------------------------------- Title qddml -- Stata program for Double Debiased Machine Learning ddml implements algorithms for causal inference aided by supervised machine learning as proposed in Double/debiased machine learning for treatment and structural parameters (Econometrics Journal, 2018). Five different models are supported, allowing for binary or continous treatment variables and endogeneity, high-dimensional controls and/or instrumental variables. ddml supports a variety of different ML programs, including but not limited to lassopack and pystacked.</description>
    </item>
    
    <item>
      <title>Installation</title>
      <link>https://statalasso.github.io/docs/ddml/installation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://statalasso.github.io/docs/ddml/installation/</guid>
      <description>Installation # You can install ddml from SSC:
ssc install ddml, replace We tend to update our Github version more regularly. You can get the lastest versions from github:
net install ddml, /// from(https://raw.githubusercontent.com/aahrens1/ddml/master) /// replace To install an older version, use for example:
net install ddml, /// from(https://raw.githubusercontent.com/aahrens1/ddml/v1.2) /// replace Please check for updates on a regular basis.
Offline installation # If you want to use ddml in an offline environment, we recommend to download the packages from the Github repositories.</description>
    </item>
    
  </channel>
</rss>
