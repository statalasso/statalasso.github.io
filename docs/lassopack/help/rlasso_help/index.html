<!doctype html><html lang=en dir=ltr>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="---------------------------------------------------------------------------------------------------------------------------------- help rlasso lassopack v1.4.2 ---------------------------------------------------------------------------------------------------------------------------------- Title rlasso -- Program for lasso and sqrt-lasso estimation with data-driven penalization Syntax rlasso depvar regressors [weight] [if exp] [in range] [ , sqrt partial(varlist) pnotpen(varlist) psolver(string) norecover noconstant fe noftools robust cluster(varlist) bw(int) kernel(string) center xdependent numsim(int) prestd tolopt(real) tolpsi(real) tolzero(real) maxiter(int) maxpsiiter(int) maxabsx lassopsi corrnumber(int) lalternative gamma(real) maq c(real) c0(real) supscore ssnumsim(int) testonly seed(real) displayall postall ols verbose vverbose ] Note: the fe option will take advantage of the ftools package (if installed) for the fixed-effects transform; the speed gains using this package can be large.">
<meta name=theme-color content="#FFFFFF">
<meta name=color-scheme content="light dark"><meta property="og:title" content="help  rlasso">
<meta property="og:description" content="---------------------------------------------------------------------------------------------------------------------------------- help rlasso lassopack v1.4.2 ---------------------------------------------------------------------------------------------------------------------------------- Title rlasso -- Program for lasso and sqrt-lasso estimation with data-driven penalization Syntax rlasso depvar regressors [weight] [if exp] [in range] [ , sqrt partial(varlist) pnotpen(varlist) psolver(string) norecover noconstant fe noftools robust cluster(varlist) bw(int) kernel(string) center xdependent numsim(int) prestd tolopt(real) tolpsi(real) tolzero(real) maxiter(int) maxpsiiter(int) maxabsx lassopsi corrnumber(int) lalternative gamma(real) maq c(real) c0(real) supscore ssnumsim(int) testonly seed(real) displayall postall ols verbose vverbose ] Note: the fe option will take advantage of the ftools package (if installed) for the fixed-effects transform; the speed gains using this package can be large.">
<meta property="og:type" content="article">
<meta property="og:url" content="http://example.org/docs/lassopack/help/rlasso_help/"><meta property="article:section" content="docs">
<title>help rlasso | Stata ML Page</title>
<link rel=manifest href=/manifest.json>
<link rel=icon href=/favicon.png type=image/x-icon>
<link rel=stylesheet href=/book.min.faa17d5e23166cd4e013165a396fc44278cb9136b0672f68e8ff906d4e5b956b.css integrity="sha256-+qF9XiMWbNTgExZaOW/EQnjLkTawZy9o6P+QbU5blWs=" crossorigin=anonymous>
<script defer src=/flexsearch.min.js></script>
<script defer src=/en.search.min.0b9fe2fc444213e5811e9db8b972dc01217779c7c9dfad976afa25ce122b529e.js integrity="sha256-C5/i/ERCE+WBHp24uXLcASF3ecfJ362XavolzhIrUp4=" crossorigin=anonymous></script>
</head>
<body dir=ltr>
<input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control>
<main class="container flex">
<aside class=book-menu>
<div class=book-menu-content>
<nav>
<h2 class=book-brand>
<a class="flex align-center" href=/><span>Stata ML Page</span>
</a>
</h2>
<div class=book-search>
<input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/>
<div class="book-search-spinner hidden"></div>
<ul id=book-search-results></ul>
</div>
<ul>
<li class=book-section-flat>
<input type=checkbox id=section-a28c195407e662cdbffd5df0c1ccdd3c class=toggle checked>
<label for=section-a28c195407e662cdbffd5df0c1ccdd3c class="flex justify-between">
<a href=http://example.org/docs/lassopack/>LASSOPACK</a>
</label>
<ul>
<li>
<a href=http://example.org/docs/lassopack/package_overview/>Package overview</a>
</li>
<li>
<a href=http://example.org/docs/lassopack/estimators/>Estimation methods</a>
</li>
<li>
<a href=http://example.org/docs/lassopack/regularized_reg/>Regularized regression</a>
</li>
<li>
<a href=http://example.org/docs/lassopack/lasso2/>Getting started</a>
</li>
<li>
<a href=http://example.org/docs/lassopack/cvlasso/>Cross-validation</a>
</li>
<li>
<a href=http://example.org/docs/lassopack/rlasso/>Rigorous lasso</a>
</li>
<li>
<input type=checkbox id=section-7b22f9a619ffc04f2040b80267ff8ec1 class=toggle>
<label for=section-7b22f9a619ffc04f2040b80267ff8ec1 class="flex justify-between">
<a href=http://example.org/docs/lassopack/lassologit/>Lassologit</a>
</label>
<ul>
<li>
<a href=http://example.org/docs/lassopack/lassologit/lassologit_demo/>Example using Spam data</a>
</li>
</ul>
</li>
<li>
<a href=http://example.org/docs/lassopack/lasso2_replication/>Comparison glmnet</a>
</li>
<li>
<input type=checkbox id=section-de33cd2a5faa36dd8a4f9fdad33eadc5 class=toggle checked>
<label for=section-de33cd2a5faa36dd8a4f9fdad33eadc5 class="flex justify-between">
<a role=button>Help files</a>
</label>
<ul>
<li>
<a href=http://example.org/docs/lassopack/help/lasso2_help/>help lasso2</a>
</li>
<li>
<a href=http://example.org/docs/lassopack/help/cvlasso_help/>help cvlasso</a>
</li>
<li>
<a href=http://example.org/docs/lassopack/help/rlasso_help/ class=active>help rlasso</a>
</li>
</ul>
</li>
<li>
<a href=http://example.org/docs/lassopack/installation/>Installation</a>
</li>
<li>
<a href=http://example.org/docs/lassopack/lassopack_cite/>Citation</a>
</li>
</ul>
</li>
<li class=book-section-flat>
<input type=checkbox id=section-1660971b512dcfeb0bcc54343ae1329f class=toggle>
<label for=section-1660971b512dcfeb0bcc54343ae1329f class="flex justify-between">
<a href=http://example.org/docs/pdslasso/>PDSLASSO</a>
</label>
<ul>
<li>
<a href=http://example.org/docs/pdslasso/pdslasso_models/>Models</a>
</li>
<li>
<a href=http://example.org/docs/pdslasso/pdslasso_demo/>Demonstration</a>
</li>
<li>
<a href=http://example.org/docs/pdslasso/pdslasso_panel/>Panel FE</a>
</li>
<li>
<a href=http://example.org/docs/pdslasso/ivlasso_help/>Help file</a>
</li>
<li>
<a href=http://example.org/docs/pdslasso/installation/>Installation</a>
</li>
<li>
<a href=http://example.org/docs/pdslasso/pdslasso_cite/>Citation</a>
</li>
</ul>
</li>
<li class=book-section-flat>
<input type=checkbox id=section-a6d0313d37b86997de2e3c697c4d2888 class=toggle>
<label for=section-a6d0313d37b86997de2e3c697c4d2888 class="flex justify-between">
<a href=http://example.org/docs/pystacked/>PYSTACKED</a>
</label>
<ul>
<li>
<a href=http://example.org/docs/pystacked/getting_started/>Getting started</a>
</li>
<li>
<a href=http://example.org/docs/pystacked/regression/>Regression</a>
</li>
<li>
<a href=http://example.org/docs/pystacked/classification/>Classification</a>
</li>
<li>
<a href=http://example.org/docs/pystacked/parallel/>Parallelization</a>
</li>
<li>
<a href=http://example.org/docs/pystacked/help/>Help file</a>
</li>
<li>
<a href=http://example.org/docs/pystacked/installation/>Installation</a>
</li>
<li>
<a href=http://example.org/docs/pystacked/citation/>Citation</a>
</li>
</ul>
</li>
<li>
<a href=http://example.org/docs/about/>About</a>
<ul>
</ul>
</li>
<li>
<a href=http://example.org/docs/papers/>Paper</a>
<ul>
</ul>
</li>
</ul>
</nav>
<script>(function(){var a=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(b){localStorage.setItem("menu.scrollTop",a.scrollTop)}),a.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>
</div>
</aside>
<div class=book-page>
<header class=book-header>
<div class="flex align-center justify-between">
<label for=menu-control>
<img src=/svg/menu.svg class=book-icon alt=Menu>
</label>
<strong>help rlasso</strong>
<label for=toc-control>
</label>
</div>
</header>
<article class=markdown>
<pre id=stlog-1 style=font-size:11px class=sthlp>----------------------------------------------------------------------------------------------------------------------------------
<b>help rlasso</b>                                                                                                       lassopack v1.4.2
----------------------------------------------------------------------------------------------------------------------------------

<b><u>Title</u></b>

    <b>rlasso</b> --  Program for lasso and sqrt-lasso estimation with data-driven penalization

<a name=stlog-1-syntax></a><b><u>Syntax</u></b>

        <b>rlasso</b> <i>depvar</i> <i>regressors</i> [<i>weight</i>] [<b>if</b> <i>exp</i>] [<b>in</b> <i>range</i>] [ <b>,</b> <b>sqrt</b> <b><u>par</u></b><b>tial(</b><i>varlist</i><b>)</b> <b><u>pnotp</u></b><b>en(</b><i>varlist</i><b>)</b> <b>psolver(</b><i>string</i><b>)</b>
              <b><u>nor</u></b><b>ecover</b> <b><u>nocons</u></b><b>tant</b> <b>fe</b> <b>noftools</b> <b><u>rob</u></b><b>ust</b> <b><u>cl</u></b><b>uster(</b><i>varlist</i><b>)</b> <b>bw(</b><i>int</i><b>)</b> <b>kernel(</b><i>string</i><b>)</b> <b>center</b> <b><u>xdep</u></b><b>endent</b> <b>numsim(</b><i>int</i><b>)</b>
              <b>prestd</b> <b><u>tol</u></b><b>opt(</b><i>real</i><b>)</b> <b><u>tolp</u></b><b>si(</b><i>real</i><b>)</b> <b><u>tolz</u></b><b>ero(</b><i>real</i><b>)</b> <b><u>maxi</u></b><b>ter(</b><i>int</i><b>)</b> <b><u>maxpsii</u></b><b>ter(</b><i>int</i><b>)</b> <b>maxabsx</b> <b>lassopsi</b> <b><u>corrn</u></b><b>umber(</b><i>int</i><b>)</b>
              <b><u>lalt</u></b><b>ernative</b> <b>gamma(</b><i>real</i><b>)</b> <b>maq</b> <b>c(</b><i>real</i><b>)</b> <b>c0(</b><i>real</i><b>)</b> <b>supscore</b> <b>ssnumsim(</b><i>int</i><b>)</b> <b>testonly</b> <b>seed(</b><i>real</i><b>)</b> <b>displayall</b> <b>postall</b> <b>ols</b>
              <b><u>ver</u></b><b>bose</b> <b><u>vver</u></b><b>bose</b> ]

        Note: the <b>fe</b> option will take advantage of the <a href=#stlog-1-SG2016><b>ftools</b></a> package (if installed) for the fixed-effects transform; the speed
              gains using this package can be large.  See help ftools or click on ssc install ftools to install.

    <i>General options</i>       Description
    ----------------------------------------------------------------------------------------------------------------------------
    <b>sqrt</b>                   use sqrt-lasso (default is standard lasso)
    <b><u>nocons</u></b><b>tant</b>             suppress constant from regression (cannot be used with <b>aweights</b> or <b>pweights</b>)
    <b>fe</b>                     fixed-effects model (requires data to be <a href=http://www.stata.com/help.cgi?xtset><b>xtset</b></a>)
    <b>noftools</b>               do not use FTOOLS package for fixed-effects transform (slower; rarely used)
    <b><u>par</u></b><b>tial(</b><i>varlist</i><b>)</b>       variables partialled-out prior to lasso estimation, including the constant (if present); to
                            partial-out just the constant, specify <b>partial(</b><i>_cons</i><b>)</b>
    <b><u>pnotp</u></b><b>en(</b><i>varlist</i><b>)</b>       variables not penalized by lasso
    <b>psolver(</b><i>string</i><b>)</b>        override default solver used for partialling out (one of: qr, qrxx, lu, luxx, svd, svdxx, chol;
                            default=qrxx)
    <b><u>nor</u></b><b>ecover</b>              suppress recovery of partialled out variables after estimation.
    <b><u>rob</u></b><b>ust</b>                 lasso penalty loadings account for heteroskedasticity
    <b><u>cl</u></b><b>uster(</b><i>varlist</i><b>)</b>       lasso penalty loadings account for clustering; both standard (1-way) and 2-way clustering supported
    <b>bw(</b><i>int</i><b>)</b>                lasso penalty loadings account for autocorrelation (AC) using bandwidth <i>int</i>; use with <b>robust</b> to
                            account for both heteroskedasticity and autocorrelation (HAC)
    <b>kernel(</b><i>string</i><b>)</b>         kernel used for HAC/AC penalty loadings (one of: bartlett, truncated, parzen, thann, thamm, daniell,
                            tent, qs; default=bartlett)
    <b>center</b>                 center moments in heteroskedastic and cluster-robust loadings
    <b>lassopsi</b>               use lasso or sqrt-lasso residuals to obtain penalty loadings (psi) (default is post-lasso)
    <b><u>corrn</u></b><b>umber(</b><i>int</i><b>)</b>        number of high-correlation regressors used to obtain initial residuals; default=5; if =0, then <i>depvar</i>
                            is used in place of residuals
    <b>prestd</b>                 standardize data prior to estimation (default is standardize during estimation via penalty loadings)
    <b>seed(</b><i>real</i><b>)</b>             set Stata's random number seed prior to <b>xdep</b> and <b>supscore</b> simulations (default=leave state unchanged)

    <i>Lambda</i>                Description
    ----------------------------------------------------------------------------------------------------------------------------
    <b><u>xdep</u></b><b>endent</b>             penalty level is estimated depending on X
    <b>numsim(</b><i>int</i><b>)</b>            number of simulations used for the X-dependent case (default=5000)
    <b><u>lalt</u></b><b>ernative</b>           alternative (less sharp) lambda0 = 2c*sqrt(N)*sqrt(2*log(2*p/gamma)) (sqrt-lasso = replace 2c with c)
    <b>gamma(</b><i>real</i><b>)</b>            "gamma" in lambda0 function (default = 0.1/log(N); cluster-lasso = 0.1/log(N_clust))
    <b>maq</b>                    (HAC/AC with truncated kernel only) "gamma" in lambda0 function = 0.1/log(N/(bw+1)); mimics
                            cluster-robust
    <b>c(</b><i>real</i><b>)</b>                "c" in lambda0 function (default = 1.1)
    <b>c0(</b><i>real</i><b>)</b>               (rarely used) "c" in lambda0 function in first iteration only when iterating to obtain penalty
                            loadings (default = 1.1)

    <i>Optimization</i>          Description
    ----------------------------------------------------------------------------------------------------------------------------
    <b><u>tolo</u></b><b>pt(</b><i>real</i><b>)</b>           tolerance for lasso shooting algorithm (default=1e-10)
    <b><u>tolp</u></b><b>si(</b><i>real</i><b>)</b>           tolerance for penalty loadings algorithm (default=1e-4)
    <b><u>tolz</u></b><b>ero(</b><i>real</i><b>)</b>          minimum below which coeffs are rounded down to zero (default=1e-4)
    <b><u>maxi</u></b><b>ter(</b><i>int</i><b>)</b>           maximum number of iterations for the lasso shooting algorithm (default=10k)
    <b><u>maxpsii</u></b><b>ter(</b><i>int</i><b>)</b>        maximum number of lasso-based iterations for penalty loadings (psi) algorithm (default=2)
    <b>maxabsx</b>                (sqrt-lasso only) use max(abs(x_ij)) as initial penalty loadings as per Belloni et al. (<a href=#stlog-1-BCW2014><b>2014</b></a>)

    <i>Sup-score test</i>        Description
    ----------------------------------------------------------------------------------------------------------------------------
    <b>supscore</b>               report sup-score test of statistical significance
    <b>testonly</b>               report only sup-score test; do not estimate lasso regression
    <b>ssgamma(</b><i>real</i><b>)</b>          test level for conservative critical value for the sup-score test (default = 0.05, i.e., 5%
                            significance level)
    <b>ssnumsim(</b><i>int</i><b>)</b>          number of simulations for sup-score test multiplier bootstrap (default=500; 0 =&gt; do not simulate)

    <i>Display and post</i>      Description
    ----------------------------------------------------------------------------------------------------------------------------
    <b>displayall</b>             display full coefficient vectors including unselected variables (default: display only selected,
                            unpenalized and partialled-out)
    <b>postall</b>                post full coefficient vector including unselected variables in e(b) (default: e(b) has only selected,
                            unpenalized and partialled-out)
    <b>ols</b>                    post OLS coefs using lasso-selected variables in e(b) (default is lasso coefs)
    <b><u>ver</u></b><b>bose</b>                show additional output
    <b><u>vver</u></b><b>bose</b>               show even more output
    <b>dots</b>                   show dots corresponding to repetitions in simulations (<b>xdep</b> and <b>supscore</b>)
    ----------------------------------------------------------------------------------------------------------------------------

    Postestimation:

        <b>predict</b> [<a href=http://www.stata.com/help.cgi?datatypes><i>type</i></a>] <a href=http://www.stata.com/help.cgi?newvar><i>newvar</i></a> [<a href=http://www.stata.com/help.cgi?if><i>if</i></a>] [<a href=http://www.stata.com/help.cgi?in><i>in</i></a>] [ <b>,</b> <b>xb</b> <b>u</b> <b>e</b> <b>ue</b> <b>xbu</b> <b>resid</b> <b>lasso</b> <b><u>noi</u></b><b>sily</b> <b>ols</b> ]

    <b>predict</b> is not currently supported after fixed-effects estimation.

    <i>Options</i>               Description
    ----------------------------------------------------------------------------------------------------------------------------
    <b>xb</b>                     generate fitted values (default)
    <b><u>r</u></b><b>esiduals</b>              generate residuals
    <b>e</b>                      generate overall error component e(it).  Only after <b>fe</b>.
    <b>ue</b>                     generate combined residuals, i.e., u(i) + e(it). Only after <b>fe</b>.
    <b>xbu</b>                    prediction including fixed effect, i.e., a + xb + u(i). Only after <b>fe</b>.
    <b>u</b>                      fixed effect, i.e., u(i). Only after <b>fe</b>.
    <b><u>noi</u></b><b>sily</b>                displays beta used for prediction.
    <b>lasso</b>                  use lasso coefficients for prediction (default is posted e(b) matrix)
    <b>ols</b>                    use OLS coefficients based on lasso-selected variables for prediction (default is posted e(b) matrix)
    ----------------------------------------------------------------------------------------------------------------------------

    Replay:

        <b>rlasso</b> [ <b>,</b> <b>displayall</b> ]

    <i>Options</i>               Description
    ----------------------------------------------------------------------------------------------------------------------------
    <b>displayall</b>             display full coefficient vectors including unselected variables (default: display only selected,
                            unpenalized and partialled-out)
    ----------------------------------------------------------------------------------------------------------------------------

    <b>rlasso</b> may be used with time-series or panel data, in which case the data must be tsset or xtset first; see help <a href=http://www.stata.com/help.cgi?tsset><b>tsset</b></a> or 
    <a href=http://www.stata.com/help.cgi?xtset><b>xtset</b></a>.

    <b>aweights</b> and <b>pweights</b> are supported; see help <a href=http://www.stata.com/help.cgi?weights><b>weights</b></a>.  <b>pweights</b> is equivalent to <b>aweights</b> + <b>robust</b>.

    All varlists may contain time-series operators or factor variables; see help <a href=http://www.stata.com/help.cgi?varlist><b>varlist</b></a>.


<b><u>Contents</u></b>

    <a href=#stlog-1-description>Description</a>
    <a href=#stlog-1-estimation>Estimation methods</a>
    <a href=#stlog-1-loadings>Penalty loadings</a>
    <a href=#stlog-1-supscore>Sup-score test of joint significance</a>
    <a href=#stlog-1-computation>Computational notes</a>
    <a href=#stlog-1-misc>Miscellaneous</a>
    <a href=#stlog-1-versions>Version notes</a>
    <a href=#stlog-1-examples>Examples of usage</a>
    <a href=#stlog-1-saved_results>Saved results</a>
    <a href=#stlog-1-references>References</a>
    <a href=#stlog-1-website>Website</a>
    <a href=#stlog-1-installation>Installation</a>
    <a href=#stlog-1-acknowledgements>Acknowledgements</a>
    <a href=#stlog-1-citation>Citation of lassopack</a>


<a name=stlog-1-description></a><b><u>Description</u></b>

    <b>rlasso</b> is a routine for estimating the coefficients of a lasso or square-root lasso (sqrt-lasso) regression where the lasso
    penalization is data-dependent and where the number of regressors p may be large and possibly greater than the number of
    observations.  The lasso (Least Absolute Shrinkage and Selection Operator, Tibshirani <a href=#stlog-1-Tib1996><b>1996</b></a>) is a regression method that uses
    regularization and the L1 norm.  <b>rlasso</b> implements a version of the lasso that allows for heteroskedastic and clustered
    errors; see Belloni et al. (<a href=#stlog-1-BCCH2012><b>2012</b></a>, <a href=#stlog-1-BCH2013><b>2013</b></a>, <a href=#stlog-1-BCH2014><b>2014</b></a>, <a href=#stlog-1-BCHK2016><b>2016</b></a>).  For an overview of <b>rlasso</b> and the theory behind it, see Ahrens et al.
    (<a href=#stlog-1-AHS2020><b>2020</b></a>)

    The default estimator implemented by <b>rlasso</b> is the lasso.  An alternative that does not involve estimating the error
    variance is the square-root-lasso (sqrt-lasso) of Belloni et al. (<a href=#stlog-1-BCW2011><b>2011</b></a>, <a href=#stlog-1-BCW2014><b>2014</b></a>), available with the <b>sqrt</b> option.

    The lasso and sqrt-lasso estimators achieve sparse solutions:  of the full set of p predictors, typically most will have
    coefficients set to zero and only s&lt;&lt;p will be non-zero.  The "post-lasso" estimator is OLS applied to the variables with
    non-zero lasso or sqrt-lasso coefficients, i.e., OLS using the variables selected by the lasso or sqrt-lasso.  The
    lasso/sqrt-lasso and post-lasso coefficients are stored in <b>e(</b><i>beta</i><b>)</b> and <b>e(</b><i>betaOLS</i><b>)</b>, respectively.  By default, <b>rlasso</b> posts
    the lasso or sqrt-lasso coefficients in <b>e(</b><i>b</i><b>)</b>.  To post in <b>e(</b><i>b</i><b>)</b> the OLS coefficients based on lasso- or sqrt-lasso-selected
    variables, use the <b>ols</b> option.

<b><u>Estimation methods</u></b>

    <b>rlasso</b> solves the following problem

        min 1/N RSS + lambda/N*||Psi*beta||_1, 
        
    where

    RSS        = sum(y(i)-x(i)'beta)^2 denotes the residual sum of squares,
    beta       is a p-dimensional parameter vector,
    lambda     is the overall penalty level,
    ||.||_1    denotes the L1-norm, i.e., sum_i(abs(a[i]));
    Psi        is a p by p diagonal matrix of predictor-specific penalty loadings. Note that <b>rlasso</b> treats Psi as a row vector.
    N          number of observations

    If the option <b>sqrt</b> is specified, <b>rlasso</b> estimates the sqrt-lasso estimator, which is defined as the solution to:

        min sqrt(1/N*RSS) + lambda/N*||Psi*beta||_1. 

    Note: the above lambda differs from the definition used in parts of the lasso and elastic net literature; see for example
    the R package <i>glmnet</i> by Friedman et al. (<a href=#stlog-1-FHT2010><b>2010</b></a>).  The objective functions here follow the format of Belloni et al. (<a href=#stlog-1-BCW2011><b>2011</b></a>,
    <a href=#stlog-1-BCCH2012><b>2012</b></a>).  Specifically, <i>lambda(r)=2*N*lambda(GN)</i> where <i>lambda(r)</i> is the penalty level used by <b>rlasso</b> and <i>lambda(GN)</i> is the
    penalty level used by <i>glmnet</i>.

    <b>rlasso</b> obtains the solutions to the lasso sqrt-lasso using coordinate descent algorithms.  The algorithm was first proposed
    by Fu (<a href=#stlog-1-FU1998><b>1998</b></a>) for the lasso (then referred to as "shooting").  For further details of how the lasso and sqrt-lasso solutions
    are obtained, see <a href=http://www.stata.com/help.cgi?lasso2><b>lasso2</b></a>.

    <b>rlasso</b> first estimates the lasso penalty level and then uses the coordinate descent algorithm to obtain the lasso
    coefficients.  For the homoskedastic case, a single penalty level lambda is applied; in the heteroskedastic and cluster
    cases, the penalty loadings vary across regressors.  The methods are discussed in detail in Belloni et al. (<a href=#stlog-1-BCCH2012><b>2012</b></a>, <a href=#stlog-1-BCH2013><b>2013</b></a>, 
    <a href=#stlog-1-BCW2014><b>2014</b></a>, <a href=#stlog-1-BCHK2016><b>2016</b></a>) and are described only briefly here.  For a detailed discussion of an R implementation of <b>rlasso</b>, see Spindler
    et al. (<a href=#stlog-1-SCH2016><b>2016</b></a>).

    For compatibility with the wider lasso literature, the documentation here uses "lambda" to refer to the penalty level that,
    combined with the possibly regressor-specific penalty loadings, is used with the estimation algorithm to obtain the lasso
    coefficients.  "lambda0" refers to the component of the overall lasso penalty level that does not depend on the error
    variance.  Note that this terminology differs from that in the R implementation of <b>rlasso</b> by Spindler et al. (<a href=#stlog-1-SCH2016><b>2016</b></a>).

    The default lambda0 for the lasso is 2c*sqrt(N)*invnormal(1-gamma/(2p)), where p is the number of penalized regressors and c
    and gamma are constants with default values of 1.1 and 0.1/log(N), respectively.  In the cluster-lasso (Belloni et al. <a href=#stlog-1-BCHK2016><b>2016</b></a>)
    the default gamma is 0.1/log(N_clust), where N_clust is the number of clusters (saved in <b>e(</b><i>N_clust</i><b>)</b>).  The default lambda0s
    for the sqrt-lasso are the same except replace 2c with c.  The constant c&gt;1.0 is a slack parameter; gamma controls the
    confidence level.  The alternative formula lambda0 = 2c*sqrt(N)*sqrt(2*log(2p/gamma)) is available with the <b>lalt</b> option.
    The constants c and gamma can be set using the <b>c(</b><i>real</i><b>)</b> and <b>gamma(</b><i>real</i><b>)</b> options.  The <b>xdep</b> option is another alternative that
    implements an "X-dependent" penalty level lambda0; see Belloni and Chernozhukov (<a href=#stlog-1-BC2011><b>2011</b></a>) and Belloni et al. (<a href=#stlog-1-BCH2013><b>2013</b></a>) for
    discussion.

    The default lambda for the lasso in the i.i.d. case is lambda0*rmse, where rmse is an estimate of the standard deviation of
    the error variance.  The sqrt-lasso differs from the standard lasso in that the penalty term lambda is pivotal in the
    homoskedastic case and does not depend on the error variance.  The default for the sqrt-lasso in the i.i.d. case is
    lambda=lambda0=c*sqrt(N)*invnormal(1-gamma/(2*p)) (note the absence of the factor of "2" vs. the lasso lambda).

<a name=stlog-1-loadings></a><b><u>Penalty loadings</u></b>

    As is standard in the lasso literature, regressors are standardized to have unit variance.  By default, standardization is
    achieved by incorporating the standard deviations of the regressors into the penalty loadings.  In the default homoskedastic
    case, the penalty loadings are the vector of standard deviations of the regressors.  The normalized penalty loadings are the
    penalty loadings normalized by the SDs of the regressors.  In the homoskedastic case the normalized penalty loadings are a
    vector of 1s.  <b>rlasso</b> saves the vector of penalty loadings, the vector of normalized penalty loadings, and the vector of SDs
    of the regressors X in <b>e(</b>.<b>)</b> macros.

    Penalty loadings are constructed after the partialling-out of unpenalized regressors and/or the FE (fixed-effects)
    transformation, if applicable.  A alternative to partialling-out unpenalized regressors with the <b>partial(</b><i>varlist</i><b>)</b> option is
    to give them penalty loadings of zero with the <b>pnotpen(</b><i>varlist</i><b>)</b> option.  By the Frisch-Waugh-Lovell Theorem for the lasso
    (Yamada <a href=#stlog-1-Yam2017><b>2017</b></a>), the estimated lasso coefficients are the same in theory (but see <a href=#stlog-1-notpen><b>below</b></a>) whether the unpenalized regressors
    are partialled-out or given zero penalty loadings, so long as the same penalty loadings are used for the penalized
    regressors in both cases.  Note that the calculation of the penalty loadings in both the <b>partial(</b>.<b>)</b> and <b>pnotpen(</b>.<b>)</b> cases
    involves adjustments for the partialled-out variables.  This is different from the <b>lasso2</b> handling of unpenalized variables
    specified in the <b>lasso2</b> option <b>notpen(</b>.<b>)</b>, where no such adjustment of the penalty loadings is made (and is why the two
    no-penalization options are named differently).

    Regressor-specific penalty loadings for the heteroskedastic and clustered cases are derived following the methods described
    in Belloni et al. (<a href=#stlog-1-BCCH2012><b>2012</b></a>, <a href=#stlog-1-BCH2013><b>2013</b></a>, <a href=#stlog-1-BCH2014><b>2014</b></a>, <a href=#stlog-1-BCW2015><b>2015</b></a>, <a href=#stlog-1-BCHK2016><b>2016</b></a>).  The penalty loadings for the heteroskedastic-robust case have elements of
    the form sqrt[avg(x^2e^2)]/sqrt[avg(e^2)] where x is a (demeaned) regressor, e is the residual, and sqrt[avg(e^2)] is the
    root mean squared error; the normalized penalty loadings have elements sqrt[avg(x^2e^2)]/(sqrt[avg(x^2)]sqrt[avg(e^2)])
    where the sqrt(avg(x^2) in the denominator is SD(x), the standard deviation of x.  This corresponds to the presentation of
    penalty loadings in Belloni et al. (<a href=#stlog-1-BCW2014><b>2014</b></a>; see Algorithm 1 but note that in their presentation, the predictors x are assumed
    already to be standardized).  NB: in the presentation we use here, the penalty loadings for the lasso and sqrt-lasso are the
    same; what differs is the overall penalty term lambda.

    The cluster-robust case is similar to the heteroskedastic case except that numerator sqrt[avg(x^2e^2)] in the
    heteroskedastic case is replaced by sqrt[avg(u_i^2)], where (using the notation of the Stata manual's discussion of the
    _robust command) u_i is the sum of x_ij*e_ij over the j members of cluster i; see Belloni et al. (<a href=#stlog-1-BCHK2016><b>2016</b></a>).  Again in the
    presentation used here, the cluster-lasso and cluster-sqrt-lasso penalty loadings are the same.  The unit vector is again
    the benchmark for the standardized penalty loadings.  NB: also following <a href=http://www.stata.com/help.cgi?_robust><b>_robust</b></a>, the denominator of avg(u_i^2) and Tbar is
    (N_clust-1).

    <b>cluster(</b><i>varname1 varname2</i><b>)</b> implements two-way cluster-robust penalty loadings (Cameron et al. <a href=#stlog-1-CGM2011><b>2011</b></a>; Thompson <a href=#stlog-1-SBT2011><b>2011</b></a>).
    "Two-way cluster-robust" means the penalty loadings accommodate arbitrary within-group correlation in two distinct
    non-nested categories defined by <i>varname1</i> and <i>varname2</i>.  Note that the asymptotic justification for the two-way
    cluster-robust approach requires both dimensions to be "large" (go off to infinity).

    Autocorrelation-consistent (AC) and heteroskedastic and autocorrelation-consistent (HAC) penalty loadings can be obtained by
    using the <b>bw(</b><i>int</i><b>)</b> option on its own (AC) or in combination with the <b>robust</b> option (HAC), where <i>int</i> specifies the bandwidth;
    see Chernozhukov et al. (<a href=#stlog-1-CHHW2020><b>2018, 2020</b></a>) and Ahrens et al. (<a href=#stlog-1-AADEKS2020><b>2020</b></a>).  Syntax and usage follows that used by <a href=http://www.stata.com/help.cgi?ivreg2><b>ivreg2</b></a>; see the <a href=http://www.stata.com/help.cgi?ivreg2><b>ivreg2</b></a>
    help file for details.  The default is to use the Bartlett kernel; this can be changed using the <b>kernel</b> option.  The full
    list of kernels available is (abbreviations in parentheses):  Bartlett (bar); Truncated (tru); Parzen (par); Tukey-Hanning
    (thann); Tukey-Hamming (thamm); Daniell (dan); Tent (ten); and Quadratic-Spectral (qua or qs).  AC and HAC penalty loadings
    can also be used for (large T) panel data; this requires the dataset to be <a href=http://www.stata.com/help.cgi?xtset><b>xtset</b></a>.

    Note that for some kernels it is possible in finite samples to obtain negative variances and hence undefined penalty
    loadings; the same is true of two-way cluster-robust.  Intutively, this arises because the covariance term in a calculation
    like var+var-2cov is "too big".  When this happens, <b>rlasso</b> issues a warning and (arbitrarily) replaces 2cov with cov.

    The <b>center</b> option centers the x_ij*e_ij terms (or in the cluster-lasso case, the u_i terms) prior to calculating the penalty
    loadings.

<a name=stlog-1-supscore></a><b><u>Sup-score test of joint significance</u></b>

    <b>rlasso</b> with the <b>supscore</b> option reports a test of the null hypothesis H0: beta_1 = ... = beta_p = 0.  i.e., a test of the
    joint significance of the regressors (or, alternatively, a test that H0: s=0; of the full set of p regressors, none is in
    the true model).  The test follows Chernozhukov et al. (<a href=#stlog-1-CCK2013><b>2013</b></a>, Appendix M); see also Belloni et al. (<a href=#stlog-1-BCCH2012><b>2012</b></a>, <a href=#stlog-1-BCH2013><b>2013</b></a>).  (The
    variables are assumed to be rescaled to be centered and with unit variance.)

    If the null hypothesis is correct and the rest of the model is well-specified (including the assumption that the regressors
    are orthogonal to the disturbance e), then E(e*x_j) = E((y-beta_0)*x_j) = 0, j=1...p where beta_0 is the intercept.  The
    sup-score statistic is S=sqrt(N)*max_j(abs(avg((y-b_0)*x_j))/(sqrt(avg(((y-b_0)*x_j)^2)))), where:  (a) the numerator
    abs(avg((y-b_0)*x_j)) is the absolute value of the average score for regressor x_j and b_0 is sample mean of y; (b) the
    denominator sqrt(avg(((y-b_0)*x_j)^2)) is the sample standard deviation of the score; (c) the statistic is sqrt(N) times the
    maximum across the p regressors of the ratio of (a) to (b).

    The p-value for the sup-score test is obtained by a multiplier bootstrap procedure simulating the statistic W, defined as
    W=sqrt(N)*max_j(abs(avg((y-b_0)*x_j*u))/(sqrt(avg(((y-b_0)*x_j)^2)))) where u is an iid standard normal variate independent
    of the data.  The <b>ssnumsim(</b><i>int</i><b>)</b> option controls the number of simulated draws (default=500); <b>ssnumsim(</b><i>0</i><b>)</b> requests that the
    sup-score statistic is reported without a simulation-based p-value.  <b>rlasso</b> also reports a conservative critical value
    (asymptotic bound) as per Belloni et al. (<a href=#stlog-1-BCCH2012><b>2012</b></a>, <a href=#stlog-1-BCCH2013><b>2013</b></a>), defined as c*invnormal(1-gamma/(2p)); this can be set by the option
    <b>ssgamma(</b><i>int</i><b>)</b> (default = 0.05).

<a name=stlog-1-computation></a><b><u>Computational notes</u></b>

    A computational alternative to the default of standardizing "on the fly" (i.e., incorporating the standardization into the
    lasso penalty loadings) is to standardize all variables to have unit variance prior to computing the lasso coefficients.
    This can be done using the <b>prestd</b> option.  The results are equivalent in theory.  The <b>prestd</b> option can lead to improved
    numerical precision or more stable results in the case of difficult problems; the cost is (a typically small) computation
    time required to standardize the data.

<a name=stlog-1-notpen></a>    Either the <b>partial(</b><i>varlist</i><b>)</b> option or the <b>pnotpen(</b><i>varlist</i><b>)</b> option can be used for variables that should not be penalized by
    the lasso.  The options are equivalent in theory (see above), but numerical results can differ in practice because of the
    different calculation methods used.  Partialling-out variables can lead to improved numerical precision or more stable
    results in the case of difficult problems vs. specifying the variables as unpenalized, but may be slower in terms of
    computation time.

    Both the <b>partial(</b><i>varlist</i><b>)</b> and <b>pnotpen(</b><i>varlist</i><b>)</b> options use least squares.  This is implemented in Mata using one of Mata's
    solvers.  In cases where the variables to be partialled out are collinear or nearly so, different solvers may generate
    different results.  Users may wish to check the stability of their results in such cases.  The <b>psolver(</b>.<b>)</b> option can be used
    to specify the Mata solver used.  The default behavior of <b>rlasso</b> to solve AX=B for X is to use the QR decomposition applied
    to (A'A) and (A'B), i.e., qrsolve((A'A),(A'B)), abbreviated qrxx.  Available options are qr, qrxx, lu, luxx, svd, svdxx,
    where, e.g., svd indicates using svsolve(A,B) and svdxx indicates using svsolve((A'A),(A'B)).  <b>rlasso</b> will warn if collinear
    variables are dropped when partialling out.

    By default the constant (if present) is not penalized if there are no regressors being partialled out; this is equivalent to
    mean-centering prior to estimation.  The exception to this is if <b>aweights</b> or <b>aweights</b> are specified, in which case the
    constant is partialled-out.  The <b>partial(</b><i>varlist</i><b>)</b> option will automatically also partial out the constant (if present); to
    partial out just the constant, specify <b>partial(</b><i>_cons</i><b>)</b>.  The within transformation implemented by the <b>fe</b> option automatically
    mean-centers the data; the <b>nocons</b> option is redundant in this case and may not be specified with this option.

    The <b>prestd</b> and <b>pnotpen(</b><i>varlist</i><b>)</b> vs. <b>partial(</b><i>varlist</i><b>)</b> options can be used as simple checks for numerical stability by
    comparing results that should be equivalent in theory.  If the results differ, the values of the minimized objective
    functions (<b>e(pmse)</b> or <b>e(prmse)</b>) can be compared.

    The <b>fe</b> fixed-effects option is equivalent to (but computationally faster and more accurate than) specifying unpenalized
    panel-specific dummies.  The fixed-effects ("within") transformation also removes the constant as well as the fixed effects.
    The panel variable used by the <b>fe</b> option is the panel variable set by <a href=http://www.stata.com/help.cgi?xtset><b>xtset</b></a>.  To use weights with fixed effects, the ftools
    must be installed.

<a name=stlog-1-misc></a><b><u>Miscellaneous</u></b>

    By default <b>rlasso</b> reports only the set of selected variables and their lasso and post-lasso coefficients; the omitted
    coefficients are not reported in the regression output.  The <b>postall</b> and <b>displayall</b> options allow the full coefficient
    vector (with coefficients of unselected variables set to zero) to be either posted in <b>e(</b><i>b</i><b>)</b> or displayed as output.

    <b>rlasso</b>, like the lasso in general, accommodates possibly perfectly-collinear sets of regressors.  Stata's <a href=http://www.stata.com/help.cgi?fvvarlist><b>factor variables</b></a>
    are supported by <b>rlasso</b> (as well as by <a href=http://www.stata.com/help.cgi?lasso2><b>lasso2</b></a>).  Users therefore have the option of specifying as regressors one or more
    complete sets of factor variables or interactions with no base levels using the <i>ibn</i> prefix.  This can be interpreted as
    allowing <b>rlasso</b> to choose the members of the base category.

    The choice of whether to use <b>partial(</b><i>varlist</i><b>)</b> or <b>pnotpen(</b><i>varlist</i><b>)</b> will depend on the circumstances faced by the user.  The
    <b>partial(</b><i>varlist</i><b>)</b> option can be helpful in dealing with data that have scaling problems or collinearity issues; in these
    cases it can be more accurate and/or achieve convergence faster than the <b>pnotpen(</b><i>varlist</i><b>)</b> option.  The <b>pnotpen(</b><i>varlist</i><b>)</b>
    option will sometimes be faster because it avoids using the pre-estimation transformation employed by <b>partial(</b><i>varlist</i><b>)</b>.  The
    two options can be used simultaneously (but not for the same variables).

    The treatment of standardization, penalization and partialling-out in <b>rlasso</b> differs from that of <b>lasso2</b>.  In the <b>rlasso</b>
    treatment, standardization incorporates the partialling-out of regressors listed in the <b>pnotpen(</b><i>varlist</i><b>)</b> list as well as
    those in the <b>partial(</b><i>varlist</i><b>)</b> list.  This is in order to maintain the equivalence of the lasso estimator irrespective of
    which option is used for unpenalized variables (see the discussion of the Frisch-Waugh-Lovell Theorem for the lasso above).
    In the <b>lasso2</b> treatment, standardization takes place after the partialling-out of only the regressors listed in the
    <b>notpen(</b><i>varlist</i><b>)</b> option.  In other words, <b>rlasso</b> adjusts the penalty loadings for any unpenalized variables; <b>lasso2</b> does not.
    For further details, see <a href=http://www.stata.com/help.cgi?lasso2><b>lasso2</b></a>.

    The initial overhead for fixed-effects estimation and/or partialling out and/or pre-estimation standardization (creating
    temporary variables and then transforming the data) can be noticable for large datasets.  For problems that involve looping
    over data, users may wish to first transform the data by hand.

    If a small number of correlations is set using the <b>corrnum(</b><i>int</i><b>)</b> option, users may want to increase the number of penalty
    loadings iterations from the default of 2 to something higher using the <b>maxpsiiter(</b><i>int</i><b>)</b> option.

    The sup-score p-value is obtained by simulation, which can be time-consuming for large datasets.  To skip this and use only
    the conservative (asymptotic bound) critical value, set the number of simulations to zero with the <b>ssnumsim(</b><i>0</i><b>)</b> option.

<a name=stlog-1-versions></a><b><u>Version notes</u></b>

    Detailed version notes can be found inside the ado files rlasso.ado and lassoutils.ado.  Noteworthy changes appear below.

    In versions of <b>lassoutils</b> prior to 1.1.01 (8 Nov 2018), the very first iteration to obtain penalty loadings set the constant
    c=0.55.  This was dropped in version 1.1.01, and the constant c is unchanged in all iterations.  To replicate the previous
    behavior of <b>rlasso</b>, use the <b>c0(</b><i>real</i><b>)</b> option.  For example, with the default value of c=1.1, to replicate the earlier
    behavior use <b>c0(</b><i>0</i>.<i>55</i><b>)</b>.

    In versions of <b>lassoutils</b> prior to 1.1.01 (8 Nov 2018), the sup-score test statistic S was N*max_j rather than sqrt(N)*max_j
    as in Chernozhukov et al. (<a href=#stlog-1-CCK2013><b>2013</b></a>), and similarly for the simulated statistic W.


<a name=stlog-1-examples></a><b><u>Examples using prostate cancer data from Hastie et al. (</u></b><a href=#stlog-1-HTF2009><b><u>2009</u></b></a><b><u>)</u></b>

    Load prostate cancer data.
        . clear
        . insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data, tab

    Estimate lasso using data-driven lambda penalty; default homoskedasticity case.
        . rlasso lpsa lcavol lweight age lbph svi lcp gleason pgg45

    Use square-root lasso instead.
        . rlasso lpsa lcavol lweight age lbph svi lcp gleason pgg45, sqrt

    Illustrate relationships between lambda, lambda0 and penalty loadings:

    Basic usage: homoskedastic case, lasso
        . rlasso lpsa lcavol lweight age lbph svi lcp gleason pgg45
    lambda=lambda0*SD is lasso penalty; incorporates the estimate of the error variance
    default lambda0 is 2c*sqrt(N)*invnormal(1-gamma/(2*p))
        . di e(lambda)
        . di e(lambda0)
    In the homoskedastic case, penalty loadings are the vector of SDs of penalized regressors
        . mat list e(ePsi)
    ...and the standardized penalty loadings are a vector of 1s.
        . mat list e(sPsi)

    Heteroskedastic case, lasso
        . rlasso lpsa lcavol lweight age lbph svi lcp gleason pgg45, robust
    lambda and lambda0 are the same as for the homoskedastic case
        . di e(lambda)
        . di e(lambda0)
    Penalty loadings account for heteroskedasticity as well as incorporating SD(x)
        . mat list e(ePsi)
    ...and the standardized penalty loadings are not a vector of 1s.
        . mat list e(sPsi)

    Homoskedastic case, sqrt-lasso
        . rlasso lpsa lcavol lweight age lbph svi lcp gleason pgg45, sqrt
    with the sqrt-lasso, the default lambda=lambda0=c*sqrt(N)*invnormal(1-gamma/(2*p));
    note the difference by a factor of 2 vs. the standard lasso lambda0
        . di e(lambda)
        . di e(lambda0)

    <b>rlasso</b> vs. <b>lasso2</b> (if installed)
        . rlasso lpsa lcavol lweight age lbph svi lcp gleason pgg45
    lambda=lambda0*SD is lasso penalty; incorporates the estimate of the error variance
    default lambda0 is 2c*sqrt(N)*invnormal(1-gamma/(2*p))
        . di %8.5f e(lambda)
    Replicate <b>rlasso</b> estimates using <b>rlasso</b> lambda and <b>lasso2</b>
        . lasso2 lpsa lcavol lweight age lbph svi lcp gleason pgg45, lambda(44.34953)

<b><u>Examples using data from Acemoglu-Johnson-Robinson (</u></b><a href=#stlog-1-AJR2001><b><u>2001</u></b></a><b><u>)</u></b>

    Load and reorder AJR data for Table 6 and Table 8 (datasets need to be in current directory).
        . clear
        . (click to download maketable6.zip from economics.mit.edu)
        . unzipfile maketable6
        . (click to download maketable8.zip from economics.mit.edu)
        . unzipfile maketable8
        . use maketable6
        . merge 1:1 shortnam using maketable8
        . keep if baseco==1
        . order shortnam logpgp95 avexpr lat_abst logem4 edes1975 avelf, first
        . order indtime euro1900 democ1 cons1 democ00a cons00a, last

    Alternatively, load AJR data from our website (no manual download required):
        . clear
        . use https://statalasso.github.io/dta/AJR.dta

    Basic usage:
        . rlasso logpgp95 lat_abst edes1975 avelf temp* humid* steplow-oilres

    Heteroskedastic-robust penalty loadings:
        . rlasso logpgp95 lat_abst edes1975 avelf temp* humid* steplow-oilres, robust

    Partialling-out vs. non-penalization:
        . rlasso logpgp95 lat_abst edes1975 avelf temp* humid* steplow-oilres, partial(lat_abst)
        . rlasso logpgp95 lat_abst edes1975 avelf temp* humid* steplow-oilres, pnotpen(lat_abst)

    Request sup-score test (H0: all betas=0):
        . rlasso logpgp95 lat_abst edes1975 avelf temp* humid* steplow-oilres, supscore

<b><u>Examples using data from Angrist-Krueger (</u></b><a href=#stlog-1-AK1991><b><u>1991</u></b></a><b><u>)</u></b>

    Load AK data and rename variables (dataset needs to be in current directory).  NB: this is a large dataset (330k
    observations) and estimations may take some time to run on some installations.
        . clear
        . (click to download asciiqob.zip from economics.mit.edu)
        . unzipfile asciiqob.zip
        . infix lnwage 1-9 edu 10-20 yob 21-31 qob 32-42 pob 43-53 using asciiqob.txt

    Alternatively, get data from our website source (no unzipping needed):
        . use https://statalasso.github.io/dta/AK91.dta

    xtset data by place of birth (state):
        . xtset pob

    State (place of birth) fixed effects; regressors are year of birth, quarter of birth and QOBxYOB.
        . rlasso edu i.yob# #i.qob, fe

    As above but explicit penalized state dummies and all categories (no base category) for all factor vars.
    Note that the (unpenalized) constant is reported.
        . rlasso edu ibn.yob# #ibn.qob ibn.pob

    State fixed effects; regressors are YOB, QOB and QOBxYOB; cluster on state.
        . rlasso edu i.yob# #i.qob, fe cluster(pob)

<b><u>Example using data from Belloni et al. (</u></b><a href=#stlog-1-BCH2015><b><u>2015</u></b></a><b><u>)</u></b>

    Load dataset on eminent domain (available at journal website).
        . clear
        . import excel using CSExampleData.xlsx, first

    Settings used in Belloni et al. (<a href=#stlog-1-BCH2015><b>2015</b></a>) - results as in text discussion (p=147):
        . rlasso NumProCase Z* BA BL DF, robust lalt corrnum(0) maxpsiiter(100) c0(0.55)
        . di e(p)

    Settings used in Belloni et al. (<a href=#stlog-1-BCH2015><b>2015</b></a>) - results as in journal replication file (p=144):
        . rlasso NumProCase Z*, robust lalt corrnum(0) maxpsiiter(100) c0(0.55)
        . di e(p)

<b><u>Examples illustrating AC/HAC penalty loadingss</u></b>

        . use http://fmwww.bc.edu/ec-p/data/wooldridge/phillips.dta
        . tsset year, yearly

    Autocorrelation-consistent (AC) penalty loadings; bandwidth=3; default kernel is Bartlett.
        . rlasso cinf L(0/10).unem, bw(3)

    Heteroskedastic- and autocorrelation-consistent (HAC) penalty loadings; bandwidth=5; kernel is quadratic-spectral.
        . rlasso cinf L(0/10).unem, bw(5) rob kernel(qs)


<a name=stlog-1-saved_results></a><b><u>Saved results</u></b>

    <b>rlasso</b> saves the following in <b>e()</b>:

    scalars       
      <b>e(N)</b>               sample size
      <b>e(N_clust)</b>         number of clusters in cluster-robust estimation; in the case of 2-way cluster-robust,
                           <b>e(N_clust)</b>=min(<b>e(N_clust1)</b>,<b>e(N_clust2)</b>)
      <b>e(N_g)</b>             number of groups in fixed-effects model
      <b>e(p)</b>               number of penalized regressors in model
      <b>e(s)</b>               number of selected regressors
      <b>e(s0)</b>              number of selected and unpenalized regressors including constant (if present)
      <b>e(lambda0)</b>         penalty level excluding rmse (default = 2c*sqrt(N)*invnormal(1-gamma/(2*p)))
      <b>e(lambda)</b>          lasso: penalty level including rmse (=lambda0*rmse); sqrt-lasso: lambda=lambda0
      <b>e(slambda)</b>         standardized lambda; equiv to lambda used on standardized data; lasso: slambda=lambda/SD(depvar);
                           sqrt-lasso: slambda=lambda0
      <b>e(c)</b>               parameter in penalty level lambda
      <b>e(gamma)</b>           parameter in penalty level lambda
      <b>e(niter)</b>           number of iterations for shooting algorithm
      <b>e(maxiter)</b>         max number of iterations for shooting algorithm
      <b>e(npsiiter)</b>        number of iterations for loadings algorithm
      <b>e(maxpsiiter)</b>      max iterations for loadings algorithm
      <b>e(r2)</b>              R-sq for lasso estimation
      <b>e(rmse)</b>            rmse using lasso resduals
      <b>e(rmseOLS)</b>         rmse using post-lasso residuals
      <b>e(pmse)</b>            minimized objective function (penalized mse, standard lasso only)
      <b>e(prmse)</b>           minimized objective function (penalized rmse, sqrt-lasso only)
      <b>e(cons)</b>            =1 if constant in model, =0 otherwise
      <b>e(fe)</b>              =1 if fixed-effects model, =0 otherwise
      <b>e(center)</b>          =1 if moments have been centered
      <b>e(bw)</b>              (HAC/AC only) bandwidth used
      <b>e(supscore)</b>        sup-score statistic
      <b>e(supscore_p)</b>      sup-score p-value
      <b>e(supscore_cv)</b>     sup-score critical value (asymptotic bound)

    macros        
      <b>e(cmd)</b>             rlasso
      <b>e(cmdline)</b>         command line
      <b>e(depvar)</b>          name of dependent variable
      <b>e(varX)</b>            all regressors
      <b>e(varXmodel)</b>       penalized regressors
      <b>e(pnotpen)</b>         unpenalized regressors
      <b>e(partial)</b>         partialled-out regressors
      <b>e(selected)</b>        selected and penalized regressors
      <b>e(selected0)</b>       all selected regressors including unpenalized and constant (if present)
      <b>e(method)</b>          lasso or sqrt-lasso
      <b>e(estimator)</b>       lasso, sqrt-lasso or post-lasso ols posted in e(b)
      <b>e(robust)</b>          heteroskedastic-robust penalty loadings
      <b>e(clustvar)</b>        variable defining clusters for cluster-robust penalty loadings; if two-way clustering is used, the
                           variables are in <b>e(</b><i>clustvar1</i><b>)</b> and <b>e(</b><i>clustvar2</i><b>)</b>
      <b>e(kernel)</b>          (HAC/AC only) kernel used
      <b>e(ivar)</b>            variable defining groups for fixed-effects model

    matrices      
      <b>e(b)</b>               posted coefficient vector
      <b>e(beta)</b>            lasso or sqrt-lasso coefficient vector
      <b>e(betaOLS)</b>         post-lasso coefficient vector
      <b>e(betaAll)</b>         full lasso or sqrt-lasso coefficient vector including omitted, factor base variables, etc.
      <b>e(betaAllOLS)</b>      full post-lasso coefficient vector including omitted, factor base variables, etc.
      <b>e(ePsi)</b>            estimated penalty loadings
      <b>e(sPsi)</b>            standardized penalty loadings (vector of 1s in homoskedastic case

    functions     
      <b>e(sample)</b>          estimation sample


<a name=stlog-1-references></a><b><u>References</u></b>

<a name=stlog-1-AJR2001></a>    Acemoglu, D., Johnson, S. and Robinson, J.A. 2001.  The colonial origins of comparative development: An empirical
        investigation.  <i>American Economic Review</i>, 91(5):1369-1401.  https://economics.mit.edu/files/4123

<a name=stlog-1-AADEKS2020></a>    Ahrens, A., Aitkens, C., Dizten, J., Ersoy, E., Kohns, D. and M.E. Schaffer. 2020.  A Theory-based Lasso for Time-Series
        Data.  Invited paper for the International Conference of Econometrics of Vietnam, January 2020.  Forthcoming in <i>Studies</i>
        <i>in Computational Intelligence</i> (Springer).

<a name=stlog-1-AHS2020></a>    Ahrens, A., Hansen, C.B. and M.E. Schaffer. 2020.  lassopack: model selection and prediction with regularized regression in
        Stata.  <i>The Stata Journal</i>, 20(1):176-235.  https://journals.sagepub.com/doi/abs/10.1177/1536867X20909697.  Working paper
        version: https://arxiv.org/abs/1901.05397.

<a name=stlog-1-AK1991></a>    Angrist, J. and Kruger, A. 1991.  Does compulsory school attendance affect schooling and earnings?  <i>Quarterly Journal of</i>
        <i>Economics</i> 106(4):979-1014.  http://www.jstor.org/stable/2937954

<a name=stlog-1-BC2011></a>    Belloni, A. and Chernozhukov, V. 2011.  High-dimensional sparse econometric models: An introduction.  In Alquier, P.,
        Gautier E., and Stoltz, G. (eds.), Inverse problems and high-dimensional estimation.  Lecture notes in statistics, vol.
        203.  Springer, Berlin, Heidelberg.  https://arxiv.org/pdf/1106.5242.pdf

<a name=stlog-1-BCW2011></a>    Belloni, A., Chernozhukov, V. and Wang, L. 2011.  Square-root lasso: Pivotal recovery of sparse signals via conic
        programming.  <i>Biometrika</i> 98:791-806.  https://doi.org/10.1214/14-AOS1204

<a name=stlog-1-BCCH2012></a>    Belloni, A., Chen, D., Chernozhukov, V. and Hansen, C. 2012.  Sparse models and methods for optimal instruments with an
        application to eminent domain.  <i>Econometrica</i> 80(6):2369-2429.  
        http://onlinelibrary.wiley.com/doi/10.3982/ECTA9626/abstract

<a name=stlog-1-BCH2013></a>    Belloni, A., Chernozhukov, V. and Hansen, C. 2013.  Inference for high-dimensional sparse econometric models.  In <i>Advances</i>
        <i>in Economics and Econometrics: 10th World Congress</i>, Vol. 3: Econometrics, Cambridge University Press: Cambridge,
        245-295.  http://arxiv.org/abs/1201.0220

<a name=stlog-1-BCH2014></a>    Belloni, A., Chernozhukov, V. and Hansen, C. 2014.  Inference on treatment effects after selection among high-dimensional
        controls.  <i>Review of Economic Studies</i> 81:608-650.  https://doi.org/10.1093/restud/rdt044

<a name=stlog-1-BCH2015></a>    Belloni, A., Chernozhukov, V. and Hansen, C. 2015.  High-dimensional methods and inference on structural and treatment
        effects.  <i>Journal of Economic Perspectives</i> 28(2):29-50.  http://www.aeaweb.org/articles.php?doi=10.1257/jep.28.2.29

<a name=stlog-1-BCHK2016></a>    Belloni, A., Chernozhukov, V., Hansen, C. and Kozbur, D. 2016.  Inference in high dimensional panel models with an
        application to gun control.  <i>Journal of Business and Economic Statistics</i> 34(4):590-605.  
        http://amstat.tandfonline.com/doi/full/10.1080/07350015.2015.1102733

<a name=stlog-1-BCW2014></a>    Belloni, A., Chernozhukov, V. and Wang, L. 2014.  Pivotal estimation via square-root-lasso in nonparametric regression.
        <i>Annals of Statistics</i> 42(2):757-788.  https://doi.org/10.1214/14-AOS1204

<a name=stlog-1-CCK2013></a>    Chernozhukov, V., Chetverikov, D. and Kato, K. 2013.  Gaussian approximations and multiplier bootstrap for maxima of sums of
        high-dimensional random vectors.  <i>Annals of Statistics</i> 41(6):2786-2819.  https://projecteuclid.org/euclid.aos/1387313390

<a name=stlog-1-CGM2011></a>    Cameron, A.C., Gelbach, J.B. and D.L. Miller.  Robust Inference with Multiway Clustering.  <i>Journal of Business &amp; Economic</i>
        <i>Statistics</i> 29(2):238-249.  https://www.jstor.org/stable/25800796.  Working paper version: NBER Technical Working Paper
        327, http://www.nber.org/papers/t0327.

<a name=stlog-1-CHHW2020></a>    Chernozhukov, V., Hardle, W.K., Huang, C. and W. Wang. 2018 (rev 2020).  LASSO-driven inference in time and space.  <i>Working</i>
        <i>paper</i>.  https://arxiv.org/abs/1806.05081

<a name=stlog-1-SG2016></a>    Correia, S. 2016.  FTOOLS: Stata module to provide alternatives to common Stata commands optimized for large datasets.  
        https://ideas.repec.org/c/boc/bocode/s458213.html

<a name=stlog-1-FHT2010></a>    Friedman, J., Hastie, T., &amp; Tibshirani, R. (2010).  Regularization Paths for Generalized Linear Models via Coordinate
        Descent.  <i>Journal of Statistical Software</i> 33(1), 1\9622.  https://doi.org/10.18637/jss.v033.i01

<a name=stlog-1-FU1998></a>    Fu, W.J.  1998.  Penalized regressions: The bridge versus the lasso.  <i>Journal of Computational and Graphical Statistics</i>
        7(3):397-416.  http://www.tandfonline.com/doi/abs/10.1080/10618600.1998.10474784

<a name=stlog-1-HTF2009></a>    Hastie, T., Tibshirani, R. and Friedman, J. 2009.  <i>The elements of statistical learning</i> (2nd ed.).  New York:
        Springer-Verlag.  https://web.stanford.edu/~hastie/ElemStatLearn/

<a name=stlog-1-SCH2016></a>    Spindler, M., Chernozhukov, V. and Hansen, C. 2016.  High-dimensional metrics.  https://cran.r-project.org/package=hdm.

<a name=stlog-1-SBT2011></a>    Thompson, S.B. 2011.  Simple formulas for standard errors that cluster by both firm and time.  <i>Journal of Financial</i>
        <i>Economics</i> 99(1):1-10.  Working paper version: http://ssrn.com/abstract=914002.

<a name=stlog-1-Tib1996></a>    Tibshirani, R. 1996.  Regression shrinkage and selection via the lasso.  <i>Journal of the Royal Statistical Society. Series B</i>
        <i>(Methodological)</i> 58(1):267-288.  https://doi.org/10.2307/2346178

<a name=stlog-1-Yam2017></a>    Yamada, H. 2017.  The Frisch-Waugh-Lovell Theorem for the lasso and the ridge regression.  <i>Communications in Statistics -</i>
        <i>Theory and Methods</i> 46(21):10897-10902.  http://dx.doi.org/10.1080/03610926.2016.1252403

<a name=stlog-1-website></a><b><u>Website</u></b>

    Please check our website https://statalasso.github.io/ for more information.

<a name=stlog-1-installation></a><b><u>Installation</u></b>

    <b>rlasso</b> is part of the <a href=http://www.stata.com/help.cgi?lassopack><b>lassopack</b></a> package.  To get the latest stable version of <a href=http://www.stata.com/help.cgi?lassopack><b>lassopack</b></a> from our website, check the
    installation instructions at https://statalasso.github.io/installation/.  We update the stable website version more
    frequently than the SSC version.  Earlier versions of <a href=http://www.stata.com/help.cgi?lassopack>lassopack</a> are also available from the website.

    To verify that <i>lassopack</i> is correctly installed, click on or type whichpkg lassopack (which requires <a href=http://www.stata.com/help.cgi?whichpkg><b>whichpkg</b></a> to be
    installed; ssc install whichpkg).

<a name=stlog-1-acknowledgements></a><b><u>Acknowledgements</u></b>

    Thanks to Alexandre Belloni for providing Matlab code for the square-root-lasso and to Sergio Correia for advice on the use
    of the FTOOLS package.


<a name=stlog-1-citation></a><b><u>Citation of rlasso</u></b>

    <b>rlasso</b> is not an official Stata command. It is a free contribution to the research community, like a paper. Please cite it
    as such:

    Ahrens, A., Hansen, C.B., Schaffer, M.E. 2018 (updated 2020).  LASSOPACK: Stata module for lasso, square-root lasso, elastic
        net, ridge, adaptive lasso estimation and cross-validation http://ideas.repec.org/c/boc/bocode/s458458.html

    Ahrens, A., Hansen, C.B. and M.E. Schaffer. 2020.  lassopack: model selection and prediction with regularized regression in
        Stata.  <i>The Stata Journal</i>, 20(1):176-235.  https://journals.sagepub.com/doi/abs/10.1177/1536867X20909697.  Working paper
        version: https://arxiv.org/abs/1901.05397.

<b><u>Authors</u></b>

        Achim Ahrens, Public Policy Group, ETH Zurich, Switzerland
        achim.ahrens@gess.ethz.ch
        
        Christian B. Hansen, University of Chicago, USA
        Christian.Hansen@chicagobooth.edu

        Mark E. Schaffer, Heriot-Watt University, UK
        m.e.schaffer@hw.ac.uk


<b><u>Also see</u></b>

       Help:  <a href=http://www.stata.com/help.cgi?lasso2><b>lasso2</b></a>, <a href=http://www.stata.com/help.cgi?cvlasso><b>cvlasso</b></a>, <a href=http://www.stata.com/help.cgi?lassologit><b>lassologit</b></a>, <a href=http://www.stata.com/help.cgi?pdslasso>pdslasso</a>, <a href=http://www.stata.com/help.cgi?ivlasso>ivlasso</a> (if installed)
</pre>
</article>
<footer class=book-footer>
<div class="flex flex-wrap justify-between">
</div>
<script>(function(){function a(c){const a=window.getSelection(),b=document.createRange();b.selectNodeContents(c),a.removeAllRanges(),a.addRange(b)}document.querySelectorAll("pre code").forEach(b=>{b.addEventListener("click",function(c){a(b.parentElement),navigator.clipboard&&navigator.clipboard.writeText(b.parentElement.textContent)})})})()</script>
</footer>
<div class=book-comments>
</div>
<label for=menu-control class="hidden book-menu-overlay"></label>
</div>
</main>
</body>
</html>