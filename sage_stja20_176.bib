





@article{doi:10.1177/1536867X20909697,
author = {Achim Ahrens and Christian B. Hansen and Mark E. Schaffer},
title ={lassopack: Model selection and prediction with regularized regression in Stata},
journal = {The Stata Journal},
volume = {20},
number = {1},
pages = {176-235},
year = {2020},
doi = {10.1177/1536867X20909697},

URL = { 
        https://doi.org/10.1177/1536867X20909697
    
},
eprint = { 
        https://doi.org/10.1177/1536867X20909697
    
}
,
    abstract = { In this article, we introduce lassopack, a suite of programs for regularized regression in Stata. lassopack implements lasso, square-root lasso, elastic net, ridge regression, adaptive lasso, and postestimation ordinary least squares. The methods are suitable for the high-dimensional setting, where the number of predictors p may be large and possibly greater than the number of observations, n. We offer three approaches for selecting the penalization (“tuning”) parameters: information criteria (implemented in lasso2), K-fold cross-validation and h-step-ahead rolling cross-validation for cross-section, panel, and time-series data (cvlasso), and theory-driven (“rigorous” or plugin) penalization for the lasso and square-root lasso for cross-section and panel data (rlasso). We discuss the theoretical framework and practical considerations for each approach. We also present Monte Carlo results to compare the performances of the penalization approaches. }
}


